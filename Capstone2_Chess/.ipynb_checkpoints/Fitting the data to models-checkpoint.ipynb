{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importting some standard packages\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "pd.options.display.max_seq_items = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_move_count</th>\n",
       "      <th>victory_status_draw</th>\n",
       "      <th>victory_status_mate</th>\n",
       "      <th>victory_status_outoftime</th>\n",
       "      <th>victory_status_resign</th>\n",
       "      <th>winner_black</th>\n",
       "      <th>winner_draw</th>\n",
       "      <th>...</th>\n",
       "      <th>opening_eco_C41</th>\n",
       "      <th>opening_eco_C42</th>\n",
       "      <th>opening_eco_C44</th>\n",
       "      <th>opening_eco_C45</th>\n",
       "      <th>opening_eco_C46</th>\n",
       "      <th>opening_eco_C50</th>\n",
       "      <th>opening_eco_C55</th>\n",
       "      <th>opening_eco_D00</th>\n",
       "      <th>opening_eco_D02</th>\n",
       "      <th>opening_eco_D20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1322</td>\n",
       "      <td>1261</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1439</td>\n",
       "      <td>1454</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>1523</td>\n",
       "      <td>1469</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>1520</td>\n",
       "      <td>1423</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         turns  white_rating  black_rating  opening_move_count  \\\n",
       "game_id                                                          \n",
       "1           16          1322          1261                   4   \n",
       "2           61          1496          1500                   3   \n",
       "3           61          1439          1454                   3   \n",
       "4           95          1523          1469                   5   \n",
       "6           33          1520          1423                  10   \n",
       "\n",
       "         victory_status_draw  victory_status_mate  victory_status_outoftime  \\\n",
       "game_id                                                                       \n",
       "1                          0                    0                         0   \n",
       "2                          0                    1                         0   \n",
       "3                          0                    1                         0   \n",
       "4                          0                    1                         0   \n",
       "6                          0                    0                         0   \n",
       "\n",
       "         victory_status_resign  winner_black  winner_draw  ...  \\\n",
       "game_id                                                    ...   \n",
       "1                            1             1            0  ...   \n",
       "2                            0             0            0  ...   \n",
       "3                            0             0            0  ...   \n",
       "4                            0             0            0  ...   \n",
       "6                            1             0            0  ...   \n",
       "\n",
       "         opening_eco_C41  opening_eco_C42  opening_eco_C44  opening_eco_C45  \\\n",
       "game_id                                                                       \n",
       "1                      0                0                0                0   \n",
       "2                      0                0                0                0   \n",
       "3                      0                0                0                0   \n",
       "4                      1                0                0                0   \n",
       "6                      0                0                0                0   \n",
       "\n",
       "         opening_eco_C46  opening_eco_C50  opening_eco_C55  opening_eco_D00  \\\n",
       "game_id                                                                       \n",
       "1                      0                0                0                0   \n",
       "2                      0                0                0                0   \n",
       "3                      0                0                0                0   \n",
       "4                      0                0                0                0   \n",
       "6                      0                0                0                1   \n",
       "\n",
       "         opening_eco_D02  opening_eco_D20  \n",
       "game_id                                    \n",
       "1                      0                0  \n",
       "2                      0                0  \n",
       "3                      1                0  \n",
       "4                      0                0  \n",
       "6                      0                0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#reprocessing my data because the last go just did not work\n",
    "df = pd.read_csv('most_popular_over_200_games.csv', index_col = 0)\n",
    "#Let's one hot the categories I want\n",
    "df_onehot = df.copy()\n",
    "df_onehot.drop(columns = 'opening_name', axis = 1, inplace = True)\n",
    "df_onehot = pd.get_dummies(df_onehot, columns=['victory_status', 'winner', 'increment_code', 'opening_eco'])\n",
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.69      1693\n",
      "           1       0.68      0.69      0.69      1664\n",
      "\n",
      "    accuracy                           0.69      3357\n",
      "   macro avg       0.69      0.69      0.69      3357\n",
      "weighted avg       0.69      0.69      0.69      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#let's start fitting the sets into logistic regression models through sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "#Before we do that we have to train test split, let's build our first model to see if we can predict 'winner_white' as a test\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "logreg = LogisticRegression(max_iter = 1000, random_state = 10)\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "    So it looks like we can predict the winner_white with about .69 percent accuracy which is fine, let's see if we can do better with black and compare them, just for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.72      0.71      1822\n",
      "           1       0.66      0.63      0.64      1535\n",
      "\n",
      "    accuracy                           0.68      3357\n",
      "   macro avg       0.68      0.67      0.68      3357\n",
      "weighted avg       0.68      0.68      0.68      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#winner_black\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw'], axis = 1), df_onehot['winner_black'], random_state = 10, test_size = 0.3)\n",
    "logreg = LogisticRegression(max_iter = 1000, random_state = 10)\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So slightly worse with predicting black with this simple log reg and our model is more or less working as intended. Now for the idea of trying to determine the opening_eco. So let's go ahead and build a for loop for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw'], axis = 1), df_onehot['winner_black'], random_state = 10, test_size = 0.3)\n",
    "logreg = LogisticRegression(max_iter = 1000, random_state = 10)\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_A00 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3077\n",
      "           1       0.92      0.84      0.88       280\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.95      0.91      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Opening: opening_eco_A04 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3270\n",
      "           1       0.00      0.00      0.00        87\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.95      0.97      0.96      3357\n",
      "\n",
      "Opening: opening_eco_A40 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3188\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.47      0.50      0.49      3357\n",
      "weighted avg       0.90      0.95      0.93      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_A45 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3273\n",
      "           1       0.00      0.00      0.00        84\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.95      0.97      0.96      3357\n",
      "\n",
      "Opening: opening_eco_B00 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3186\n",
      "           1       0.00      0.00      0.00       171\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.47      0.50      0.49      3357\n",
      "weighted avg       0.90      0.95      0.92      3357\n",
      "\n",
      "Opening: opening_eco_B01 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3151\n",
      "           1       0.00      0.00      0.00       206\n",
      "\n",
      "    accuracy                           0.94      3357\n",
      "   macro avg       0.47      0.50      0.48      3357\n",
      "weighted avg       0.88      0.94      0.91      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_B07 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3272\n",
      "           1       0.00      0.00      0.00        85\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.95      0.97      0.96      3357\n",
      "\n",
      "Opening: opening_eco_B20 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3188\n",
      "           1       0.00      0.00      0.00       169\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.47      0.50      0.49      3357\n",
      "weighted avg       0.90      0.95      0.93      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_B21 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3287\n",
      "           1       0.00      0.00      0.00        70\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.96      0.98      0.97      3357\n",
      "\n",
      "Opening: opening_eco_B30 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3290\n",
      "           1       0.00      0.00      0.00        67\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.96      0.98      0.97      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_B50 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3283\n",
      "           1       0.00      0.00      0.00        74\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.96      0.98      0.97      3357\n",
      "\n",
      "Opening: opening_eco_C00 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      3099\n",
      "           1       0.00      0.00      0.00       258\n",
      "\n",
      "    accuracy                           0.92      3357\n",
      "   macro avg       0.46      0.50      0.48      3357\n",
      "weighted avg       0.85      0.92      0.89      3357\n",
      "\n",
      "Opening: opening_eco_C02 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3277\n",
      "           1       0.17      0.04      0.06        80\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.57      0.52      0.52      3357\n",
      "weighted avg       0.96      0.97      0.96      3357\n",
      "\n",
      "Opening: opening_eco_C20 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3185\n",
      "           1       0.00      0.00      0.00       172\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.47      0.50      0.49      3357\n",
      "weighted avg       0.90      0.95      0.92      3357\n",
      "\n",
      "Opening: opening_eco_C40 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3221\n",
      "           1       0.00      0.00      0.00       136\n",
      "\n",
      "    accuracy                           0.96      3357\n",
      "   macro avg       0.48      0.50      0.49      3357\n",
      "weighted avg       0.92      0.96      0.94      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_C41 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.93      1.00      0.96      3122\n",
      "           1       0.00      0.00      0.00       235\n",
      "\n",
      "    accuracy                           0.93      3357\n",
      "   macro avg       0.46      0.50      0.48      3357\n",
      "weighted avg       0.86      0.93      0.90      3357\n",
      "\n",
      "Opening: opening_eco_C42 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98      3249\n",
      "           1       0.00      0.00      0.00       108\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.48      0.50      0.49      3357\n",
      "weighted avg       0.94      0.97      0.95      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_C44 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3266\n",
      "           1       0.00      0.00      0.00        91\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.95      0.97      0.96      3357\n",
      "\n",
      "Opening: opening_eco_C45 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.99      0.98      3261\n",
      "           1       0.14      0.03      0.05        96\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.56      0.51      0.52      3357\n",
      "weighted avg       0.95      0.97      0.96      3357\n",
      "\n",
      "Opening: opening_eco_C46 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3278\n",
      "           1       0.00      0.00      0.00        79\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.95      0.98      0.96      3357\n",
      "\n",
      "Opening: opening_eco_C50 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.99      0.97      3200\n",
      "           1       0.07      0.01      0.02       157\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.51      0.50      0.50      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Opening: opening_eco_C55 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99      3266\n",
      "           1       0.00      0.00      0.00        91\n",
      "\n",
      "    accuracy                           0.97      3357\n",
      "   macro avg       0.49      0.50      0.49      3357\n",
      "weighted avg       0.95      0.97      0.96      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opening: opening_eco_D00 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      1.00      0.97      3151\n",
      "           1       0.00      0.00      0.00       206\n",
      "\n",
      "    accuracy                           0.94      3357\n",
      "   macro avg       0.47      0.50      0.48      3357\n",
      "weighted avg       0.88      0.94      0.91      3357\n",
      "\n",
      "Opening: opening_eco_D02 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      1.00      0.98      3236\n",
      "           1       0.00      0.00      0.00       121\n",
      "\n",
      "    accuracy                           0.96      3357\n",
      "   macro avg       0.48      0.50      0.49      3357\n",
      "weighted avg       0.93      0.96      0.95      3357\n",
      "\n",
      "Opening: opening_eco_D20 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      1.00      0.99      3292\n",
      "           1       0.00      0.00      0.00        65\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.49      0.50      0.50      3357\n",
      "weighted avg       0.96      0.98      0.97      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "opening_eco_list = ['opening_eco_A00', 'opening_eco_A04',\n",
    "       'opening_eco_A40', 'opening_eco_A45', 'opening_eco_B00',\n",
    "       'opening_eco_B01', 'opening_eco_B07', 'opening_eco_B20',\n",
    "       'opening_eco_B21', 'opening_eco_B30', 'opening_eco_B50',\n",
    "       'opening_eco_C00', 'opening_eco_C02', 'opening_eco_C20',\n",
    "       'opening_eco_C40', 'opening_eco_C41', 'opening_eco_C42',\n",
    "       'opening_eco_C44', 'opening_eco_C45', 'opening_eco_C46',\n",
    "       'opening_eco_C50', 'opening_eco_C55', 'opening_eco_D00',\n",
    "       'opening_eco_D02', 'opening_eco_D20']\n",
    "\n",
    "for opening in opening_eco_list:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = opening_eco_list, axis = 1), df_onehot[opening], random_state = 1001, test_size = 0.3)\n",
    "    logreg = LogisticRegression(max_iter = 1000, random_state = 1001)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    prediction = logreg.predict(X_test)\n",
    "    print('Opening: {} \\n Report: \\n {}'.format(opening, classification_report(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is pretty much what I expected, just not enough information from the outside of a game to predict it, but why on earth is A00, the uncommon opening, have so much accuracy? This is what I'm going to dive into more here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random_state: 0 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3072\n",
      "           1       0.90      0.84      0.87       285\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.94      0.91      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Random_state: 10 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3085\n",
      "           1       0.91      0.83      0.87       272\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.95      0.91      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Random_state: 20 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3082\n",
      "           1       0.91      0.86      0.89       275\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.95      0.93      0.94      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Random_state: 30 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3059\n",
      "           1       0.91      0.81      0.85       298\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.94      0.90      0.92      3357\n",
      "weighted avg       0.97      0.98      0.97      3357\n",
      "\n",
      "Random_state: 40 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3092\n",
      "           1       0.91      0.85      0.88       265\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.95      0.92      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Random_state: 50 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3089\n",
      "           1       0.90      0.84      0.86       268\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.94      0.91      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Random_state: 60 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3067\n",
      "           1       0.92      0.82      0.86       290\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.95      0.91      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Random_state: 70 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3083\n",
      "           1       0.89      0.84      0.87       274\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.94      0.92      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n",
      "Random_state: 80 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99      3071\n",
      "           1       0.89      0.81      0.85       286\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.94      0.90      0.92      3357\n",
      "weighted avg       0.97      0.98      0.97      3357\n",
      "\n",
      "Random_state: 90 \n",
      " Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      3083\n",
      "           1       0.89      0.86      0.88       274\n",
      "\n",
      "    accuracy                           0.98      3357\n",
      "   macro avg       0.94      0.93      0.93      3357\n",
      "weighted avg       0.98      0.98      0.98      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#to make sure it's not a fluke let's do it with random sets   \n",
    "for randr in range(0,100,10):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = opening_eco_list, axis = 1), df_onehot['opening_eco_A00'], random_state = randr, test_size = 0.3)\n",
    "    logreg = LogisticRegression(max_iter = 1000, random_state = randr)\n",
    "    logreg.fit(X_train, y_train)\n",
    "    prediction = logreg.predict(X_test)\n",
    "    print('Random_state: {} \\n Report: \\n {}'.format(randr, classification_report(y_test, prediction)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>victory_status</th>\n",
       "      <th>winner</th>\n",
       "      <th>increment_code</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_eco</th>\n",
       "      <th>opening_name</th>\n",
       "      <th>opening_move_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>39</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1381</td>\n",
       "      <td>1272</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>58</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1251</td>\n",
       "      <td>1545</td>\n",
       "      <td>A00</td>\n",
       "      <td>Crab Opening</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>96</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1290</td>\n",
       "      <td>1270</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>39</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1304</td>\n",
       "      <td>1292</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>28</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1211</td>\n",
       "      <td>1280</td>\n",
       "      <td>A00</td>\n",
       "      <td>Crab Opening</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>24</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Blitz</td>\n",
       "      <td>1361</td>\n",
       "      <td>1383</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>114</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1713</td>\n",
       "      <td>1558</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening: Indian Defense</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>48</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1942</td>\n",
       "      <td>1611</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>78</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1475</td>\n",
       "      <td>1605</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>65</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Classical</td>\n",
       "      <td>1790</td>\n",
       "      <td>1874</td>\n",
       "      <td>A00</td>\n",
       "      <td>Polish Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>20</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1620</td>\n",
       "      <td>1607</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>339</th>\n",
       "      <td>124</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1677</td>\n",
       "      <td>1627</td>\n",
       "      <td>A00</td>\n",
       "      <td>Polish Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>11</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1238</td>\n",
       "      <td>985</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>78</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1016</td>\n",
       "      <td>1126</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>59</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1367</td>\n",
       "      <td>1866</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>50</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1377</td>\n",
       "      <td>1667</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>393</th>\n",
       "      <td>52</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Blitz</td>\n",
       "      <td>1376</td>\n",
       "      <td>1469</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>47</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Classical</td>\n",
       "      <td>959</td>\n",
       "      <td>1357</td>\n",
       "      <td>A00</td>\n",
       "      <td>Creepy Crawly Formation: Classical Defense</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>405</th>\n",
       "      <td>76</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Classical</td>\n",
       "      <td>959</td>\n",
       "      <td>1357</td>\n",
       "      <td>A00</td>\n",
       "      <td>Creepy Crawly Formation: Classical Defense</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>51</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1462</td>\n",
       "      <td>1464</td>\n",
       "      <td>A00</td>\n",
       "      <td>Global Opening</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>40</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1154</td>\n",
       "      <td>1676</td>\n",
       "      <td>A00</td>\n",
       "      <td>Mieses Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>477</th>\n",
       "      <td>48</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1102</td>\n",
       "      <td>1685</td>\n",
       "      <td>A00</td>\n",
       "      <td>Polish Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>537</th>\n",
       "      <td>74</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1250</td>\n",
       "      <td>1156</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>557</th>\n",
       "      <td>50</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1070</td>\n",
       "      <td>1112</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>629</th>\n",
       "      <td>51</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Blitz</td>\n",
       "      <td>1261</td>\n",
       "      <td>1237</td>\n",
       "      <td>A00</td>\n",
       "      <td>Mieses Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>32</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1209</td>\n",
       "      <td>1265</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van Geet Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>703</th>\n",
       "      <td>60</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1500</td>\n",
       "      <td>1478</td>\n",
       "      <td>A00</td>\n",
       "      <td>Kadas Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>43</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1444</td>\n",
       "      <td>1465</td>\n",
       "      <td>A00</td>\n",
       "      <td>Polish Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>56</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1605</td>\n",
       "      <td>1698</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>48</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1622</td>\n",
       "      <td>1681</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>822</th>\n",
       "      <td>103</td>\n",
       "      <td>outoftime</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1710</td>\n",
       "      <td>1618</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>5</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1894</td>\n",
       "      <td>1539</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>38</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1902</td>\n",
       "      <td>1811</td>\n",
       "      <td>A00</td>\n",
       "      <td>Polish Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>959</th>\n",
       "      <td>41</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Classical</td>\n",
       "      <td>1458</td>\n",
       "      <td>1980</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening: Slav Formation</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>972</th>\n",
       "      <td>42</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1297</td>\n",
       "      <td>1500</td>\n",
       "      <td>A00</td>\n",
       "      <td>Mieses Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>981</th>\n",
       "      <td>27</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1862</td>\n",
       "      <td>1387</td>\n",
       "      <td>A00</td>\n",
       "      <td>Gedult's Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1023</th>\n",
       "      <td>129</td>\n",
       "      <td>draw</td>\n",
       "      <td>draw</td>\n",
       "      <td>Classical</td>\n",
       "      <td>1500</td>\n",
       "      <td>1500</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1047</th>\n",
       "      <td>16</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1328</td>\n",
       "      <td>1712</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1160</th>\n",
       "      <td>80</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Blitz</td>\n",
       "      <td>1500</td>\n",
       "      <td>1644</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1180</th>\n",
       "      <td>68</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Blitz</td>\n",
       "      <td>1299</td>\n",
       "      <td>1513</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>75</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1602</td>\n",
       "      <td>1502</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1208</th>\n",
       "      <td>62</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Blitz</td>\n",
       "      <td>1707</td>\n",
       "      <td>1734</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1210</th>\n",
       "      <td>57</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1185</td>\n",
       "      <td>1222</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1230</th>\n",
       "      <td>52</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1235</td>\n",
       "      <td>1272</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1272</th>\n",
       "      <td>57</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1500</td>\n",
       "      <td>1501</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1316</th>\n",
       "      <td>53</td>\n",
       "      <td>mate</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1500</td>\n",
       "      <td>1104</td>\n",
       "      <td>A00</td>\n",
       "      <td>Mieses Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1339</th>\n",
       "      <td>68</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1327</td>\n",
       "      <td>1327</td>\n",
       "      <td>A00</td>\n",
       "      <td>Van't Kruijs Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1349</th>\n",
       "      <td>11</td>\n",
       "      <td>resign</td>\n",
       "      <td>white</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1223</td>\n",
       "      <td>1313</td>\n",
       "      <td>A00</td>\n",
       "      <td>Grob Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464</th>\n",
       "      <td>56</td>\n",
       "      <td>resign</td>\n",
       "      <td>black</td>\n",
       "      <td>Classical</td>\n",
       "      <td>1464</td>\n",
       "      <td>1413</td>\n",
       "      <td>A00</td>\n",
       "      <td>Hungarian Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1472</th>\n",
       "      <td>32</td>\n",
       "      <td>mate</td>\n",
       "      <td>black</td>\n",
       "      <td>Rapid</td>\n",
       "      <td>1500</td>\n",
       "      <td>1407</td>\n",
       "      <td>A00</td>\n",
       "      <td>Kadas Opening</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         turns victory_status winner increment_code  white_rating  \\\n",
       "game_id                                                             \n",
       "10          39           mate  white          Rapid          1381   \n",
       "83          58           mate  black          Rapid          1251   \n",
       "193         96         resign  black          Rapid          1290   \n",
       "195         39           mate  white          Rapid          1304   \n",
       "215         28           mate  black          Rapid          1211   \n",
       "240         24         resign  white          Blitz          1361   \n",
       "266        114           mate  black          Rapid          1713   \n",
       "289         48         resign  black          Rapid          1942   \n",
       "306         78           mate  black          Rapid          1475   \n",
       "314         65         resign  white      Classical          1790   \n",
       "320         20         resign  black          Rapid          1620   \n",
       "339        124         resign  black          Rapid          1677   \n",
       "369         11           mate  white          Rapid          1238   \n",
       "375         78         resign  black          Rapid          1016   \n",
       "388         59         resign  black          Rapid          1367   \n",
       "390         50           mate  black          Rapid          1377   \n",
       "393         52         resign  black          Blitz          1376   \n",
       "403         47         resign  white      Classical           959   \n",
       "405         76           mate  black      Classical           959   \n",
       "416         51         resign  white          Rapid          1462   \n",
       "475         40         resign  black          Rapid          1154   \n",
       "477         48         resign  black          Rapid          1102   \n",
       "537         74           mate  black          Rapid          1250   \n",
       "557         50           mate  black          Rapid          1070   \n",
       "629         51         resign  white          Blitz          1261   \n",
       "690         32           mate  black          Rapid          1209   \n",
       "703         60         resign  black          Rapid          1500   \n",
       "713         43         resign  white          Rapid          1444   \n",
       "795         56           mate  black          Rapid          1605   \n",
       "797         48           mate  black          Rapid          1622   \n",
       "822        103      outoftime  white          Rapid          1710   \n",
       "865          5           mate  white          Rapid          1894   \n",
       "889         38         resign  white          Rapid          1902   \n",
       "959         41         resign  black      Classical          1458   \n",
       "972         42           mate  black          Rapid          1297   \n",
       "981         27         resign  black          Rapid          1862   \n",
       "1023       129           draw   draw      Classical          1500   \n",
       "1047        16         resign  black          Rapid          1328   \n",
       "1160        80           mate  black          Blitz          1500   \n",
       "1180        68           mate  black          Blitz          1299   \n",
       "1190        75         resign  black          Rapid          1602   \n",
       "1208        62         resign  black          Blitz          1707   \n",
       "1210        57         resign  white          Rapid          1185   \n",
       "1230        52         resign  black          Rapid          1235   \n",
       "1272        57         resign  white          Rapid          1500   \n",
       "1316        53           mate  white          Rapid          1500   \n",
       "1339        68           mate  black          Rapid          1327   \n",
       "1349        11         resign  white          Rapid          1223   \n",
       "1464        56         resign  black      Classical          1464   \n",
       "1472        32           mate  black          Rapid          1500   \n",
       "\n",
       "         black_rating opening_eco                                opening_name  \\\n",
       "game_id                                                                         \n",
       "10               1272         A00                        Van't Kruijs Opening   \n",
       "83               1545         A00                                Crab Opening   \n",
       "193              1270         A00                           Hungarian Opening   \n",
       "195              1292         A00                        Van't Kruijs Opening   \n",
       "215              1280         A00                                Crab Opening   \n",
       "240              1383         A00                        Van't Kruijs Opening   \n",
       "266              1558         A00           Hungarian Opening: Indian Defense   \n",
       "289              1611         A00                        Van't Kruijs Opening   \n",
       "306              1605         A00                           Hungarian Opening   \n",
       "314              1874         A00                              Polish Opening   \n",
       "320              1607         A00                        Van't Kruijs Opening   \n",
       "339              1627         A00                              Polish Opening   \n",
       "369               985         A00                        Van't Kruijs Opening   \n",
       "375              1126         A00                        Van't Kruijs Opening   \n",
       "388              1866         A00                        Van't Kruijs Opening   \n",
       "390              1667         A00                           Hungarian Opening   \n",
       "393              1469         A00                        Van't Kruijs Opening   \n",
       "403              1357         A00  Creepy Crawly Formation: Classical Defense   \n",
       "405              1357         A00  Creepy Crawly Formation: Classical Defense   \n",
       "416              1464         A00                              Global Opening   \n",
       "475              1676         A00                              Mieses Opening   \n",
       "477              1685         A00                              Polish Opening   \n",
       "537              1156         A00                           Hungarian Opening   \n",
       "557              1112         A00                        Van't Kruijs Opening   \n",
       "629              1237         A00                              Mieses Opening   \n",
       "690              1265         A00                            Van Geet Opening   \n",
       "703              1478         A00                               Kadas Opening   \n",
       "713              1465         A00                              Polish Opening   \n",
       "795              1698         A00                        Van't Kruijs Opening   \n",
       "797              1681         A00                        Van't Kruijs Opening   \n",
       "822              1618         A00                        Van't Kruijs Opening   \n",
       "865              1539         A00                        Van't Kruijs Opening   \n",
       "889              1811         A00                              Polish Opening   \n",
       "959              1980         A00           Hungarian Opening: Slav Formation   \n",
       "972              1500         A00                              Mieses Opening   \n",
       "981              1387         A00                            Gedult's Opening   \n",
       "1023             1500         A00                        Van't Kruijs Opening   \n",
       "1047             1712         A00                        Van't Kruijs Opening   \n",
       "1160             1644         A00                        Van't Kruijs Opening   \n",
       "1180             1513         A00                           Hungarian Opening   \n",
       "1190             1502         A00                        Van't Kruijs Opening   \n",
       "1208             1734         A00                        Van't Kruijs Opening   \n",
       "1210             1222         A00                        Van't Kruijs Opening   \n",
       "1230             1272         A00                        Van't Kruijs Opening   \n",
       "1272             1501         A00                           Hungarian Opening   \n",
       "1316             1104         A00                              Mieses Opening   \n",
       "1339             1327         A00                        Van't Kruijs Opening   \n",
       "1349             1313         A00                                Grob Opening   \n",
       "1464             1413         A00                           Hungarian Opening   \n",
       "1472             1407         A00                               Kadas Opening   \n",
       "\n",
       "         opening_move_count  \n",
       "game_id                      \n",
       "10                        1  \n",
       "83                        3  \n",
       "193                       1  \n",
       "195                       1  \n",
       "215                       3  \n",
       "240                       1  \n",
       "266                       2  \n",
       "289                       1  \n",
       "306                       1  \n",
       "314                       1  \n",
       "320                       1  \n",
       "339                       1  \n",
       "369                       1  \n",
       "375                       1  \n",
       "388                       1  \n",
       "390                       1  \n",
       "393                       1  \n",
       "403                       4  \n",
       "405                       4  \n",
       "416                       3  \n",
       "475                       1  \n",
       "477                       1  \n",
       "537                       1  \n",
       "557                       1  \n",
       "629                       1  \n",
       "690                       1  \n",
       "703                       1  \n",
       "713                       1  \n",
       "795                       1  \n",
       "797                       1  \n",
       "822                       1  \n",
       "865                       1  \n",
       "889                       1  \n",
       "959                       4  \n",
       "972                       1  \n",
       "981                       1  \n",
       "1023                      1  \n",
       "1047                      1  \n",
       "1160                      1  \n",
       "1180                      1  \n",
       "1190                      1  \n",
       "1208                      1  \n",
       "1210                      1  \n",
       "1230                      1  \n",
       "1272                      1  \n",
       "1316                      1  \n",
       "1339                      1  \n",
       "1349                      1  \n",
       "1464                      1  \n",
       "1472                      1  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing some research to see what A00 has in common with each other\n",
    "df.loc[df['opening_eco'] == 'A00'].head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like it is the opening move count of 1 that the all have in common. A shame, this is not an exciting find. Moving on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.00      0.00      0.00       252\n",
      "           2       0.37      0.07      0.12       587\n",
      "           3       0.24      0.97      0.39       785\n",
      "           4       0.37      0.03      0.06       621\n",
      "           5       0.22      0.03      0.05       462\n",
      "           6       0.00      0.00      0.00       258\n",
      "           7       0.00      0.00      0.00       169\n",
      "           8       0.00      0.00      0.00       130\n",
      "           9       0.00      0.00      0.00        51\n",
      "          10       0.00      0.00      0.00        18\n",
      "          11       0.00      0.00      0.00        17\n",
      "          12       0.00      0.00      0.00         4\n",
      "          13       0.00      0.00      0.00         1\n",
      "          14       0.00      0.00      0.00         1\n",
      "          15       0.00      0.00      0.00         1\n",
      "          16       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.25      3357\n",
      "   macro avg       0.08      0.07      0.04      3357\n",
      "weighted avg       0.22      0.25      0.13      3357\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#So modeling the winner isn't too exciting, let's see if we can try and predict opening_move_count\n",
    "#let's do white rating first\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['opening_move_count'], axis = 1), df_onehot['opening_move_count'], random_state = 10, test_size = 0.3)\n",
    "logreg = LogisticRegression(max_iter = 500, random_state = 10)\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Really just looks like it's guessing. Okay, enough with the exploration. Let's try other models and see if we can predict successfully the winner of a game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 2, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67      1693\n",
      "           1       0.66      0.38      0.48      1664\n",
      "\n",
      "    accuracy                           0.60      3357\n",
      "   macro avg       0.61      0.59      0.58      3357\n",
      "weighted avg       0.61      0.60      0.58      3357\n",
      "\n",
      "Neighbors: 3, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1693\n",
      "           1       0.62      0.61      0.62      1664\n",
      "\n",
      "    accuracy                           0.62      3357\n",
      "   macro avg       0.62      0.62      0.62      3357\n",
      "weighted avg       0.62      0.62      0.62      3357\n",
      "\n",
      "Neighbors: 4, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.66      1693\n",
      "           1       0.65      0.46      0.54      1664\n",
      "\n",
      "    accuracy                           0.61      3357\n",
      "   macro avg       0.62      0.61      0.60      3357\n",
      "weighted avg       0.62      0.61      0.60      3357\n",
      "\n",
      "Neighbors: 5, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1693\n",
      "           1       0.62      0.62      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 6, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66      1693\n",
      "           1       0.66      0.50      0.57      1664\n",
      "\n",
      "    accuracy                           0.62      3357\n",
      "   macro avg       0.63      0.62      0.62      3357\n",
      "weighted avg       0.63      0.62      0.62      3357\n",
      "\n",
      "Neighbors: 7, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1693\n",
      "           1       0.63      0.62      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 8, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66      1693\n",
      "           1       0.65      0.52      0.58      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.62      0.62      3357\n",
      "weighted avg       0.63      0.63      0.62      3357\n",
      "\n",
      "Neighbors: 9, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1693\n",
      "           1       0.63      0.63      0.63      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.64      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Neighbors: 10, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66      1693\n",
      "           1       0.66      0.53      0.59      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 11, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1693\n",
      "           1       0.63      0.61      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 12, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66      1693\n",
      "           1       0.66      0.54      0.59      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.64      0.63      0.63      3357\n",
      "weighted avg       0.64      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 13, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1693\n",
      "           1       0.64      0.62      0.63      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.64      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Neighbors: 14, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66      1693\n",
      "           1       0.66      0.56      0.60      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.63      3357\n",
      "weighted avg       0.64      0.64      0.63      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "for n in range(2,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Neighbors: {}, \\n {}'.format(n, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Got a little worse here, let's try decision trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.91      0.67      1693\n",
      "           1       0.67      0.17      0.28      1664\n",
      "\n",
      "    accuracy                           0.55      3357\n",
      "   macro avg       0.60      0.54      0.47      3357\n",
      "weighted avg       0.60      0.55      0.48      3357\n",
      "\n",
      "Depth: 3 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.72      0.31      0.44      1693\n",
      "           1       0.56      0.88      0.68      1664\n",
      "\n",
      "    accuracy                           0.59      3357\n",
      "   macro avg       0.64      0.59      0.56      3357\n",
      "weighted avg       0.64      0.59      0.56      3357\n",
      "\n",
      "Depth: 4 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1693\n",
      "           1       0.63      0.62      0.63      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Depth: 5 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.51      0.59      1693\n",
      "           1       0.61      0.78      0.68      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.66      0.64      0.64      3357\n",
      "weighted avg       0.66      0.64      0.64      3357\n",
      "\n",
      "Depth: 6 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1693\n",
      "           1       0.66      0.64      0.65      1664\n",
      "\n",
      "    accuracy                           0.66      3357\n",
      "   macro avg       0.66      0.66      0.66      3357\n",
      "weighted avg       0.66      0.66      0.66      3357\n",
      "\n",
      "Depth: 7 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.62      0.65      1693\n",
      "           1       0.65      0.70      0.67      1664\n",
      "\n",
      "    accuracy                           0.66      3357\n",
      "   macro avg       0.66      0.66      0.66      3357\n",
      "weighted avg       0.66      0.66      0.66      3357\n",
      "\n",
      "Depth: 8 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.63      0.65      1693\n",
      "           1       0.64      0.68      0.66      1664\n",
      "\n",
      "    accuracy                           0.65      3357\n",
      "   macro avg       0.66      0.65      0.65      3357\n",
      "weighted avg       0.66      0.65      0.65      3357\n",
      "\n",
      "Depth: 9 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.62      0.64      1693\n",
      "           1       0.64      0.69      0.66      1664\n",
      "\n",
      "    accuracy                           0.65      3357\n",
      "   macro avg       0.65      0.65      0.65      3357\n",
      "weighted avg       0.65      0.65      0.65      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#going to iterate over some different depths\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "for depth in range(2,10):\n",
    "    dtc = DecisionTreeClassifier(max_depth = depth, random_state =10, max_features = None, min_samples_leaf = 10)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    print('Depth: {} \\n {}'.format(depth, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kind of hitting a ceiling here at about .67, which is good enough to place a bet, but not good enough to put in a paper. I would like to try SVM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C: 0.05 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.69      0.69      1693\n",
      "           1       0.68      0.68      0.68      1664\n",
      "\n",
      "    accuracy                           0.68      3357\n",
      "   macro avg       0.68      0.68      0.68      3357\n",
      "weighted avg       0.68      0.68      0.68      3357\n",
      "\n",
      "C: 0.1 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68      1693\n",
      "           1       0.68      0.68      0.68      1664\n",
      "\n",
      "    accuracy                           0.68      3357\n",
      "   macro avg       0.68      0.68      0.68      3357\n",
      "weighted avg       0.68      0.68      0.68      3357\n",
      "\n",
      "C: 0.15 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.69      1693\n",
      "           1       0.68      0.69      0.68      1664\n",
      "\n",
      "    accuracy                           0.68      3357\n",
      "   macro avg       0.68      0.68      0.68      3357\n",
      "weighted avg       0.68      0.68      0.68      3357\n",
      "\n",
      "C: 0.2 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.68      0.68      1693\n",
      "           1       0.68      0.69      0.68      1664\n",
      "\n",
      "    accuracy                           0.68      3357\n",
      "   macro avg       0.68      0.68      0.68      3357\n",
      "weighted avg       0.68      0.68      0.68      3357\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-130-060c72c2cec4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0.05\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.25\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0msvm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkernel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'linear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mC\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'C: {} \\n {}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    198\u001b[0m         \u001b[0mseed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrnd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miinfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'i'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 199\u001b[1;33m         \u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msolver_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkernel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_seed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    200\u001b[0m         \u001b[1;31m# see comment on the other call to np.iinfo in this file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py\u001b[0m in \u001b[0;36m_dense_fit\u001b[1;34m(self, X, y, sample_weight, solver_type, kernel, random_seed)\u001b[0m\n\u001b[0;32m    256\u001b[0m                 \u001b[0mcache_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcache_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m                 \u001b[0mgamma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_gamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepsilon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mepsilon\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 258\u001b[1;33m                 max_iter=self.max_iter, random_seed=random_seed)\n\u001b[0m\u001b[0;32m    259\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_from_fit_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "\n",
    "for c in [0.05, 0.1, 0.15, 0.2, 0.25]:\n",
    "    svm = SVC(kernel = 'linear', C = c, random_state = 10)\n",
    "    svm.fit(X_train, y_train)\n",
    "    y_pred = svm.predict(X_test)\n",
    "    print('C: {} \\n {}'.format(c, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like we're just not getting any better, SVM isn't doing any better than logreg. again I will say that this is pretty interesting. I want to do logreg again without victory status. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>turns</th>\n",
       "      <th>white_rating</th>\n",
       "      <th>black_rating</th>\n",
       "      <th>opening_move_count</th>\n",
       "      <th>victory_status_draw</th>\n",
       "      <th>victory_status_mate</th>\n",
       "      <th>victory_status_outoftime</th>\n",
       "      <th>victory_status_resign</th>\n",
       "      <th>winner_black</th>\n",
       "      <th>winner_draw</th>\n",
       "      <th>...</th>\n",
       "      <th>opening_eco_C41</th>\n",
       "      <th>opening_eco_C42</th>\n",
       "      <th>opening_eco_C44</th>\n",
       "      <th>opening_eco_C45</th>\n",
       "      <th>opening_eco_C46</th>\n",
       "      <th>opening_eco_C50</th>\n",
       "      <th>opening_eco_C55</th>\n",
       "      <th>opening_eco_D00</th>\n",
       "      <th>opening_eco_D02</th>\n",
       "      <th>opening_eco_D20</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>game_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16</td>\n",
       "      <td>1322</td>\n",
       "      <td>1261</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>61</td>\n",
       "      <td>1496</td>\n",
       "      <td>1500</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>61</td>\n",
       "      <td>1439</td>\n",
       "      <td>1454</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>1523</td>\n",
       "      <td>1469</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>1520</td>\n",
       "      <td>1423</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         turns  white_rating  black_rating  opening_move_count  \\\n",
       "game_id                                                          \n",
       "1           16          1322          1261                   4   \n",
       "2           61          1496          1500                   3   \n",
       "3           61          1439          1454                   3   \n",
       "4           95          1523          1469                   5   \n",
       "6           33          1520          1423                  10   \n",
       "\n",
       "         victory_status_draw  victory_status_mate  victory_status_outoftime  \\\n",
       "game_id                                                                       \n",
       "1                          0                    0                         0   \n",
       "2                          0                    1                         0   \n",
       "3                          0                    1                         0   \n",
       "4                          0                    1                         0   \n",
       "6                          0                    0                         0   \n",
       "\n",
       "         victory_status_resign  winner_black  winner_draw  ...  \\\n",
       "game_id                                                    ...   \n",
       "1                            1             1            0  ...   \n",
       "2                            0             0            0  ...   \n",
       "3                            0             0            0  ...   \n",
       "4                            0             0            0  ...   \n",
       "6                            1             0            0  ...   \n",
       "\n",
       "         opening_eco_C41  opening_eco_C42  opening_eco_C44  opening_eco_C45  \\\n",
       "game_id                                                                       \n",
       "1                      0                0                0                0   \n",
       "2                      0                0                0                0   \n",
       "3                      0                0                0                0   \n",
       "4                      1                0                0                0   \n",
       "6                      0                0                0                0   \n",
       "\n",
       "         opening_eco_C46  opening_eco_C50  opening_eco_C55  opening_eco_D00  \\\n",
       "game_id                                                                       \n",
       "1                      0                0                0                0   \n",
       "2                      0                0                0                0   \n",
       "3                      0                0                0                0   \n",
       "4                      0                0                0                0   \n",
       "6                      0                0                0                1   \n",
       "\n",
       "         opening_eco_D02  opening_eco_D20  \n",
       "game_id                                    \n",
       "1                      0                0  \n",
       "2                      0                0  \n",
       "3                      1                0  \n",
       "4                      0                0  \n",
       "6                      0                0  \n",
       "\n",
       "[5 rows x 40 columns]"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.70      0.67      1693\n",
      "           1       0.67      0.62      0.64      1664\n",
      "\n",
      "    accuracy                           0.66      3357\n",
      "   macro avg       0.66      0.66      0.66      3357\n",
      "weighted avg       0.66      0.66      0.66      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getting rid of victory statuses\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw', 'victory_status_mate', 'victory_status_outoftime', 'victory_status_resign'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "logreg = LogisticRegression(max_iter = 1000, random_state = 10)\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.96      0.68      1693\n",
      "           1       0.74      0.10      0.18      1664\n",
      "\n",
      "    accuracy                           0.54      3357\n",
      "   macro avg       0.63      0.53      0.43      3357\n",
      "weighted avg       0.63      0.54      0.43      3357\n",
      "\n",
      "Depth: 3 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60      1693\n",
      "           1       0.60      0.64      0.62      1664\n",
      "\n",
      "    accuracy                           0.61      3357\n",
      "   macro avg       0.61      0.61      0.61      3357\n",
      "weighted avg       0.61      0.61      0.61      3357\n",
      "\n",
      "Depth: 4 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.61      0.61      1693\n",
      "           1       0.60      0.60      0.60      1664\n",
      "\n",
      "    accuracy                           0.61      3357\n",
      "   macro avg       0.61      0.61      0.61      3357\n",
      "weighted avg       0.61      0.61      0.61      3357\n",
      "\n",
      "Depth: 5 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.54      0.59      1693\n",
      "           1       0.61      0.72      0.66      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.64      0.63      0.63      3357\n",
      "weighted avg       0.64      0.63      0.63      3357\n",
      "\n",
      "Depth: 6 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.62      0.63      1693\n",
      "           1       0.62      0.64      0.63      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Depth: 7 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.56      0.61      1693\n",
      "           1       0.62      0.71      0.66      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.63      3357\n",
      "weighted avg       0.64      0.64      0.63      3357\n",
      "\n",
      "Depth: 8 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.76      0.68      1693\n",
      "           1       0.68      0.53      0.60      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.65      0.64      0.64      3357\n",
      "weighted avg       0.65      0.64      0.64      3357\n",
      "\n",
      "Depth: 9 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66      1693\n",
      "           1       0.66      0.53      0.58      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.62      3357\n",
      "weighted avg       0.63      0.63      0.62      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getting rid of victory status\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#going to iterate over some different depths\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw', 'victory_status_mate', 'victory_status_outoftime', 'victory_status_resign'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "for depth in range(2,10):\n",
    "    dtc = DecisionTreeClassifier(max_depth = depth, random_state =10, max_features = None, min_samples_leaf = 10)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    print('Depth: {} \\n {}'.format(depth, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 2, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67      1693\n",
      "           1       0.65      0.38      0.48      1664\n",
      "\n",
      "    accuracy                           0.59      3357\n",
      "   macro avg       0.61      0.59      0.57      3357\n",
      "weighted avg       0.61      0.59      0.58      3357\n",
      "\n",
      "Neighbors: 3, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1693\n",
      "           1       0.62      0.61      0.62      1664\n",
      "\n",
      "    accuracy                           0.62      3357\n",
      "   macro avg       0.62      0.62      0.62      3357\n",
      "weighted avg       0.62      0.62      0.62      3357\n",
      "\n",
      "Neighbors: 4, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.66      1693\n",
      "           1       0.65      0.46      0.54      1664\n",
      "\n",
      "    accuracy                           0.61      3357\n",
      "   macro avg       0.62      0.61      0.60      3357\n",
      "weighted avg       0.62      0.61      0.60      3357\n",
      "\n",
      "Neighbors: 5, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.63      1693\n",
      "           1       0.62      0.62      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 6, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66      1693\n",
      "           1       0.66      0.50      0.57      1664\n",
      "\n",
      "    accuracy                           0.62      3357\n",
      "   macro avg       0.63      0.62      0.62      3357\n",
      "weighted avg       0.63      0.62      0.62      3357\n",
      "\n",
      "Neighbors: 7, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1693\n",
      "           1       0.63      0.62      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 8, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66      1693\n",
      "           1       0.65      0.52      0.58      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.62      0.62      3357\n",
      "weighted avg       0.63      0.63      0.62      3357\n",
      "\n",
      "Neighbors: 9, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1693\n",
      "           1       0.63      0.63      0.63      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.64      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Neighbors: 10, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.67      1693\n",
      "           1       0.66      0.53      0.59      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.64      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 11, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1693\n",
      "           1       0.63      0.61      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 12, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.72      0.66      1693\n",
      "           1       0.66      0.54      0.59      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.64      0.63      0.63      3357\n",
      "weighted avg       0.64      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 13, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1693\n",
      "           1       0.64      0.62      0.63      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.64      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Neighbors: 14, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66      1693\n",
      "           1       0.66      0.56      0.60      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.63      3357\n",
      "weighted avg       0.64      0.64      0.63      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw', 'victory_status_mate', 'victory_status_outoftime', 'victory_status_resign'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "for n in range(2,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Neighbors: {}, \\n {}'.format(n, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting rid of the victory statuses reduces the effectiveness. But this makes sense because the models can most likely figure out that having 'draw' is a give away"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3199\n",
      "           1       0.00      0.00      0.00       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.48      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Depth: 3 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3199\n",
      "           1       0.00      0.00      0.00       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.48      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Depth: 4 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.98      3199\n",
      "           1       0.00      0.00      0.00       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.48      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Depth: 5 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3199\n",
      "           1       0.08      0.01      0.01       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.52      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Depth: 6 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3199\n",
      "           1       0.08      0.01      0.01       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.52      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Depth: 7 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3199\n",
      "           1       0.08      0.01      0.01       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.52      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Depth: 8 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3199\n",
      "           1       0.08      0.01      0.01       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.52      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n",
      "Depth: 9 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      1.00      0.97      3199\n",
      "           1       0.08      0.01      0.01       158\n",
      "\n",
      "    accuracy                           0.95      3357\n",
      "   macro avg       0.52      0.50      0.49      3357\n",
      "weighted avg       0.91      0.95      0.93      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trying draw\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#going to iterate over some different depths\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw', 'victory_status_mate', 'victory_status_outoftime', 'victory_status_resign'], axis = 1), df_onehot['winner_draw'], random_state = 10, test_size = 0.3)\n",
    "for depth in range(2,10):\n",
    "    dtc = DecisionTreeClassifier(max_depth = depth, random_state =10, max_features = None, min_samples_leaf = 10)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    print('Depth: {} \\n {}'.format(depth, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "seems like this is improbable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.92      0.71      1822\n",
      "           1       0.69      0.20      0.31      1535\n",
      "\n",
      "    accuracy                           0.59      3357\n",
      "   macro avg       0.63      0.56      0.51      3357\n",
      "weighted avg       0.63      0.59      0.53      3357\n",
      "\n",
      "Depth: 3 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.63      0.63      1822\n",
      "           1       0.57      0.58      0.57      1535\n",
      "\n",
      "    accuracy                           0.61      3357\n",
      "   macro avg       0.60      0.60      0.60      3357\n",
      "weighted avg       0.61      0.61      0.61      3357\n",
      "\n",
      "Depth: 4 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.79      0.70      1822\n",
      "           1       0.64      0.44      0.52      1535\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.62      0.61      3357\n",
      "weighted avg       0.63      0.63      0.62      3357\n",
      "\n",
      "Depth: 5 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68      1822\n",
      "           1       0.61      0.51      0.56      1535\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.62      0.62      0.62      3357\n",
      "weighted avg       0.62      0.63      0.62      3357\n",
      "\n",
      "Depth: 6 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.75      0.69      1822\n",
      "           1       0.63      0.50      0.55      1535\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.62      0.62      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Depth: 7 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.71      0.68      1822\n",
      "           1       0.62      0.56      0.59      1535\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.64      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Depth: 8 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.73      0.69      1822\n",
      "           1       0.63      0.53      0.57      1535\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.63      0.63      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Depth: 9 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.66      0.67      0.66      1822\n",
      "           1       0.60      0.59      0.59      1535\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#trying black again\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#going to iterate over some different depths\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw', 'victory_status_mate', 'victory_status_outoftime', 'victory_status_resign'], axis = 1), df_onehot['winner_black'], random_state = 10, test_size = 0.3)\n",
    "for depth in range(2,10):\n",
    "    dtc = DecisionTreeClassifier(max_depth = depth, random_state =10, max_features = None, min_samples_leaf = 10)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    print('Depth: {} \\n {}'.format(depth, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So after we get rid of winning conditions it sort of reduces down to 64% accuracy. Let's try and get rid of just victory status draws.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.68      0.68      1693\n",
      "           1       0.67      0.68      0.68      1664\n",
      "\n",
      "    accuracy                           0.68      3357\n",
      "   macro avg       0.68      0.68      0.68      3357\n",
      "weighted avg       0.68      0.68      0.68      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getting rid of just status draw\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "logreg = LogisticRegression(max_iter = 1000, random_state = 10)\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 2, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.80      0.67      1693\n",
      "           1       0.66      0.38      0.48      1664\n",
      "\n",
      "    accuracy                           0.60      3357\n",
      "   macro avg       0.61      0.59      0.58      3357\n",
      "weighted avg       0.61      0.60      0.58      3357\n",
      "\n",
      "Neighbors: 3, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.64      0.63      1693\n",
      "           1       0.62      0.61      0.62      1664\n",
      "\n",
      "    accuracy                           0.62      3357\n",
      "   macro avg       0.62      0.62      0.62      3357\n",
      "weighted avg       0.62      0.62      0.62      3357\n",
      "\n",
      "Neighbors: 4, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.76      0.66      1693\n",
      "           1       0.65      0.46      0.54      1664\n",
      "\n",
      "    accuracy                           0.61      3357\n",
      "   macro avg       0.62      0.61      0.60      3357\n",
      "weighted avg       0.62      0.61      0.60      3357\n",
      "\n",
      "Neighbors: 5, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1693\n",
      "           1       0.62      0.62      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 6, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.74      0.66      1693\n",
      "           1       0.66      0.50      0.57      1664\n",
      "\n",
      "    accuracy                           0.62      3357\n",
      "   macro avg       0.63      0.62      0.62      3357\n",
      "weighted avg       0.63      0.62      0.62      3357\n",
      "\n",
      "Neighbors: 7, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.64      0.64      1693\n",
      "           1       0.63      0.62      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 8, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66      1693\n",
      "           1       0.65      0.52      0.58      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.62      0.62      3357\n",
      "weighted avg       0.63      0.63      0.62      3357\n",
      "\n",
      "Neighbors: 9, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.64      0.64      1693\n",
      "           1       0.63      0.63      0.63      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.64      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Neighbors: 10, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.73      0.66      1693\n",
      "           1       0.66      0.53      0.59      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 11, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.65      0.64      1693\n",
      "           1       0.63      0.61      0.62      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.63      0.63      0.63      3357\n",
      "weighted avg       0.63      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 12, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.72      0.66      1693\n",
      "           1       0.66      0.54      0.59      1664\n",
      "\n",
      "    accuracy                           0.63      3357\n",
      "   macro avg       0.64      0.63      0.63      3357\n",
      "weighted avg       0.64      0.63      0.63      3357\n",
      "\n",
      "Neighbors: 13, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.66      0.65      1693\n",
      "           1       0.64      0.62      0.63      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.64      3357\n",
      "weighted avg       0.64      0.64      0.64      3357\n",
      "\n",
      "Neighbors: 14, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.71      0.66      1693\n",
      "           1       0.66      0.56      0.60      1664\n",
      "\n",
      "    accuracy                           0.64      3357\n",
      "   macro avg       0.64      0.64      0.63      3357\n",
      "weighted avg       0.64      0.64      0.63      3357\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw'], axis = 1), df_onehot['winner_white'], random_state = 10, test_size = 0.3)\n",
    "for n in range(2,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Neighbors: {}, \\n {}'.format(n, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I want to get rid of draws and test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_onehot_nodraw = df_onehot.copy()\n",
    "df_onehot_nodraw.drop(df_onehot_nodraw[df_onehot_nodraw.winner_draw == 1].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.60      0.63      1579\n",
      "           1       0.65      0.71      0.68      1632\n",
      "\n",
      "    accuracy                           0.66      3211\n",
      "   macro avg       0.66      0.66      0.65      3211\n",
      "weighted avg       0.66      0.66      0.65      3211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#getting rid of just status draw\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot_nodraw.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw'], axis = 1), df_onehot_nodraw['winner_white'], random_state = 10, test_size = 0.3)\n",
    "logreg = LogisticRegression(max_iter = 1000, random_state = 10)\n",
    "logreg.fit(X_train, y_train)\n",
    "prediction = logreg.predict(X_test)\n",
    "print(classification_report(y_test, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors: 2, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.76      0.65      1579\n",
      "           1       0.65      0.41      0.50      1632\n",
      "\n",
      "    accuracy                           0.59      3211\n",
      "   macro avg       0.60      0.59      0.57      3211\n",
      "weighted avg       0.60      0.59      0.57      3211\n",
      "\n",
      "Neighbors: 3, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59      1579\n",
      "           1       0.61      0.64      0.62      1632\n",
      "\n",
      "    accuracy                           0.61      3211\n",
      "   macro avg       0.61      0.61      0.61      3211\n",
      "weighted avg       0.61      0.61      0.61      3211\n",
      "\n",
      "Neighbors: 4, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.58      0.71      0.64      1579\n",
      "           1       0.64      0.51      0.57      1632\n",
      "\n",
      "    accuracy                           0.61      3211\n",
      "   macro avg       0.61      0.61      0.60      3211\n",
      "weighted avg       0.61      0.61      0.60      3211\n",
      "\n",
      "Neighbors: 5, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.60      1579\n",
      "           1       0.61      0.64      0.63      1632\n",
      "\n",
      "    accuracy                           0.61      3211\n",
      "   macro avg       0.61      0.61      0.61      3211\n",
      "weighted avg       0.61      0.61      0.61      3211\n",
      "\n",
      "Neighbors: 6, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.68      0.63      1579\n",
      "           1       0.64      0.55      0.59      1632\n",
      "\n",
      "    accuracy                           0.61      3211\n",
      "   macro avg       0.62      0.62      0.61      3211\n",
      "weighted avg       0.62      0.61      0.61      3211\n",
      "\n",
      "Neighbors: 7, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.58      0.60      1579\n",
      "           1       0.62      0.66      0.64      1632\n",
      "\n",
      "    accuracy                           0.62      3211\n",
      "   macro avg       0.62      0.62      0.62      3211\n",
      "weighted avg       0.62      0.62      0.62      3211\n",
      "\n",
      "Neighbors: 8, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63      1579\n",
      "           1       0.63      0.57      0.60      1632\n",
      "\n",
      "    accuracy                           0.61      3211\n",
      "   macro avg       0.61      0.61      0.61      3211\n",
      "weighted avg       0.61      0.61      0.61      3211\n",
      "\n",
      "Neighbors: 9, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.59      0.60      1579\n",
      "           1       0.62      0.65      0.64      1632\n",
      "\n",
      "    accuracy                           0.62      3211\n",
      "   macro avg       0.62      0.62      0.62      3211\n",
      "weighted avg       0.62      0.62      0.62      3211\n",
      "\n",
      "Neighbors: 10, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.66      0.63      1579\n",
      "           1       0.64      0.58      0.61      1632\n",
      "\n",
      "    accuracy                           0.62      3211\n",
      "   macro avg       0.62      0.62      0.62      3211\n",
      "weighted avg       0.62      0.62      0.62      3211\n",
      "\n",
      "Neighbors: 11, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      1579\n",
      "           1       0.62      0.66      0.64      1632\n",
      "\n",
      "    accuracy                           0.63      3211\n",
      "   macro avg       0.63      0.63      0.62      3211\n",
      "weighted avg       0.63      0.63      0.63      3211\n",
      "\n",
      "Neighbors: 12, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.65      0.63      1579\n",
      "           1       0.64      0.61      0.63      1632\n",
      "\n",
      "    accuracy                           0.63      3211\n",
      "   macro avg       0.63      0.63      0.63      3211\n",
      "weighted avg       0.63      0.63      0.63      3211\n",
      "\n",
      "Neighbors: 13, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      1579\n",
      "           1       0.63      0.67      0.64      1632\n",
      "\n",
      "    accuracy                           0.63      3211\n",
      "   macro avg       0.63      0.63      0.63      3211\n",
      "weighted avg       0.63      0.63      0.63      3211\n",
      "\n",
      "Neighbors: 14, \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.66      0.64      1579\n",
      "           1       0.65      0.61      0.63      1632\n",
      "\n",
      "    accuracy                           0.64      3211\n",
      "   macro avg       0.64      0.64      0.64      3211\n",
      "weighted avg       0.64      0.64      0.64      3211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot_nodraw.drop(columns = ['winner_white', 'winner_black', 'winner_draw', 'victory_status_draw'], axis = 1), df_onehot_nodraw['winner_white'], random_state = 10, test_size = 0.3)\n",
    "for n in range(2,15):\n",
    "    knn = KNeighborsClassifier(n_neighbors = n)\n",
    "    knn.fit(X_train, y_train)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    print('Neighbors: {}, \\n {}'.format(n, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nice! this makes me a feel a bit better that we have gone through this again without draw. This makes it seem we are still able to guess the victory by more than half, which is pretty incredibly for a chess game. Let's do Decision tree quickly\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Depth: 2 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.18      0.28      1579\n",
      "           1       0.54      0.94      0.69      1632\n",
      "\n",
      "    accuracy                           0.56      3211\n",
      "   macro avg       0.64      0.56      0.49      3211\n",
      "weighted avg       0.64      0.56      0.49      3211\n",
      "\n",
      "Depth: 3 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.58      0.59      1579\n",
      "           1       0.61      0.65      0.63      1632\n",
      "\n",
      "    accuracy                           0.61      3211\n",
      "   macro avg       0.61      0.61      0.61      3211\n",
      "weighted avg       0.61      0.61      0.61      3211\n",
      "\n",
      "Depth: 4 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.65      0.62      1579\n",
      "           1       0.63      0.59      0.61      1632\n",
      "\n",
      "    accuracy                           0.62      3211\n",
      "   macro avg       0.62      0.62      0.62      3211\n",
      "weighted avg       0.62      0.62      0.62      3211\n",
      "\n",
      "Depth: 5 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.55      0.59      1579\n",
      "           1       0.62      0.71      0.66      1632\n",
      "\n",
      "    accuracy                           0.63      3211\n",
      "   macro avg       0.63      0.63      0.63      3211\n",
      "weighted avg       0.63      0.63      0.63      3211\n",
      "\n",
      "Depth: 6 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.58      0.61      1579\n",
      "           1       0.63      0.69      0.66      1632\n",
      "\n",
      "    accuracy                           0.64      3211\n",
      "   macro avg       0.64      0.64      0.64      3211\n",
      "weighted avg       0.64      0.64      0.64      3211\n",
      "\n",
      "Depth: 7 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.63      0.63      1579\n",
      "           1       0.64      0.65      0.64      1632\n",
      "\n",
      "    accuracy                           0.64      3211\n",
      "   macro avg       0.64      0.64      0.64      3211\n",
      "weighted avg       0.64      0.64      0.64      3211\n",
      "\n",
      "Depth: 8 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61      1579\n",
      "           1       0.63      0.66      0.65      1632\n",
      "\n",
      "    accuracy                           0.63      3211\n",
      "   macro avg       0.63      0.63      0.63      3211\n",
      "weighted avg       0.63      0.63      0.63      3211\n",
      "\n",
      "Depth: 9 \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.61      0.66      0.63      1579\n",
      "           1       0.64      0.60      0.62      1632\n",
      "\n",
      "    accuracy                           0.63      3211\n",
      "   macro avg       0.63      0.63      0.63      3211\n",
      "weighted avg       0.63      0.63      0.63      3211\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#white without draws \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#going to iterate over some different depths\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_onehot_nodraw.drop(columns = ['winner_white', 'winner_black', 'winner_draw'], axis = 1), df_onehot_nodraw['winner_white'], random_state = 10, test_size = 0.3)\n",
    "for depth in range(2,10):\n",
    "    dtc = DecisionTreeClassifier(max_depth = depth, random_state =10, max_features = None, min_samples_leaf = 10)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    y_pred = dtc.predict(X_test)\n",
    "    print('Depth: {} \\n {}'.format(depth, classification_report(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Log reg is the best model, so this is the model I am going to use, although I am very satisfied with the consistency across all of the models. Being more than 50%, with this small dataset, without having access to more openings, without having access to more diverse games, I feel is pretty good. I have an inkling that the more games we get the more we are able to predict the winner of the game based on the opening, we just need more data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
