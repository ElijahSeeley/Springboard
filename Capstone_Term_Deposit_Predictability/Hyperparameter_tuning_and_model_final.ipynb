{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>in_default</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>personal_loan</th>\n",
       "      <th>contact_method</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>prev_outcome</th>\n",
       "      <th>term_deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education in_default  avg_yearly_balance  \\\n",
       "0   58    management  married   tertiary         no                2143   \n",
       "1   44    technician   single  secondary         no                  29   \n",
       "2   33  entrepreneur  married  secondary         no                   2   \n",
       "3   47   blue-collar  married    unknown         no                1506   \n",
       "4   33       unknown   single    unknown         no                   1   \n",
       "\n",
       "  housing_loan personal_loan contact_method  day  month  duration  \\\n",
       "0          yes            no        unknown    5      5       261   \n",
       "1          yes            no        unknown    5      5       151   \n",
       "2          yes           yes        unknown    5      5        76   \n",
       "3          yes            no        unknown    5      5        92   \n",
       "4           no            no        unknown    5      5       198   \n",
       "\n",
       "   campaign_contacts  prev_days  previous_contacts prev_outcome term_deposit  \n",
       "0                  1         -1                  0      unknown           no  \n",
       "1                  1         -1                  0      unknown           no  \n",
       "2                  1         -1                  0      unknown           no  \n",
       "3                  1         -1                  0      unknown           no  \n",
       "4                  1         -1                  0      unknown           no  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ori = pd.DataFrame(pd.read_csv('Peruvian_Bank_Data/clean_df.csv'))\n",
    "df_ori.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#looking to get a coefficient reading so we are going to process the data with normalization and throw into logreg\n",
    "df = df_ori.copy()\n",
    "df = pd.get_dummies(data = df, columns = ['in_default', 'job', 'marital', 'education', 'contact_method', 'prev_outcome', 'housing_loan', 'personal_loan']) \n",
    "df_X = df.drop(columns = ['term_deposit'])\n",
    "df_y = df['term_deposit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size = 0.3, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normalizing the X sets\n",
    "X_train = normalize(X_train, axis = 0)\n",
    "X_test = normalize(X_test, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(data = X_train, columns = df_X.columns)\n",
    "X_test = pd.DataFrame(data = X_test, columns = df_X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train, y_train)\n",
    "logregcoefs = abs(logreg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>in_default_no</th>\n",
       "      <th>in_default_yes</th>\n",
       "      <th>...</th>\n",
       "      <th>contact_method_telephone</th>\n",
       "      <th>contact_method_unknown</th>\n",
       "      <th>prev_outcome_failure</th>\n",
       "      <th>prev_outcome_other</th>\n",
       "      <th>prev_outcome_success</th>\n",
       "      <th>prev_outcome_unknown</th>\n",
       "      <th>housing_loan_no</th>\n",
       "      <th>housing_loan_yes</th>\n",
       "      <th>personal_loan_no</th>\n",
       "      <th>personal_loan_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.82362</td>\n",
       "      <td>0.641157</td>\n",
       "      <td>4.376595</td>\n",
       "      <td>4.332708</td>\n",
       "      <td>5.835529</td>\n",
       "      <td>2.955073</td>\n",
       "      <td>1.162786</td>\n",
       "      <td>1.577131</td>\n",
       "      <td>4.658281</td>\n",
       "      <td>1.11858</td>\n",
       "      <td>...</td>\n",
       "      <td>0.988941</td>\n",
       "      <td>4.892867</td>\n",
       "      <td>1.342457</td>\n",
       "      <td>0.401059</td>\n",
       "      <td>9.987566</td>\n",
       "      <td>5.526496</td>\n",
       "      <td>1.388485</td>\n",
       "      <td>5.386779</td>\n",
       "      <td>3.805039</td>\n",
       "      <td>3.194765</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       age  avg_yearly_balance       day     month  duration  \\\n",
       "0  4.82362            0.641157  4.376595  4.332708  5.835529   \n",
       "\n",
       "   campaign_contacts  prev_days  previous_contacts  in_default_no  \\\n",
       "0           2.955073   1.162786           1.577131       4.658281   \n",
       "\n",
       "   in_default_yes  ...  contact_method_telephone  contact_method_unknown  \\\n",
       "0         1.11858  ...                  0.988941                4.892867   \n",
       "\n",
       "   prev_outcome_failure  prev_outcome_other  prev_outcome_success  \\\n",
       "0              1.342457            0.401059              9.987566   \n",
       "\n",
       "   prev_outcome_unknown  housing_loan_no  housing_loan_yes  personal_loan_no  \\\n",
       "0              5.526496         1.388485          5.386779          3.805039   \n",
       "\n",
       "   personal_loan_yes  \n",
       "0           3.194765  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coefs = pd.DataFrame(data = logregcoefs, columns = df_X.columns)\n",
    "#df_coefs = normalize(df_coefs)\n",
    "#df_coefs = pd.DataFrame(data = df_coefs, columns = df_X.columns)\n",
    "df_coefs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            age  avg_yearly_balance  day  month  duration  campaign_contacts  \\\n",
      "13976  0.363636           -0.127183   10      7  0.023148           0.000000   \n",
      "42022  0.467532            0.208785   28     10  0.555556           0.000000   \n",
      "17593  0.428571           -0.177908   29      7 -0.314815           0.016129   \n",
      "24489  0.350649            1.153464   17     11 -0.546296           0.000000   \n",
      "44180  0.155844           -0.168351   14      7  0.754630           0.129032   \n",
      "\n",
      "       prev_days  previous_contacts  in_default_no  in_default_yes  ...  \\\n",
      "13976        0.0           0.000000              1               0  ...   \n",
      "42022        0.0           0.000000              1               0  ...   \n",
      "17593        0.0           0.000000              1               0  ...   \n",
      "24489      132.0           0.003636              1               0  ...   \n",
      "44180        0.0           0.000000              1               0  ...   \n",
      "\n",
      "       contact_method_telephone  contact_method_unknown  prev_outcome_failure  \\\n",
      "13976                         0                       0                     0   \n",
      "42022                         0                       0                     0   \n",
      "17593                         0                       0                     0   \n",
      "24489                         0                       0                     1   \n",
      "44180                         1                       0                     0   \n",
      "\n",
      "       prev_outcome_other  prev_outcome_success  prev_outcome_unknown  \\\n",
      "13976                   0                     0                     1   \n",
      "42022                   0                     0                     1   \n",
      "17593                   0                     0                     1   \n",
      "24489                   0                     0                     0   \n",
      "44180                   0                     0                     1   \n",
      "\n",
      "       housing_loan_no  housing_loan_yes  personal_loan_no  personal_loan_yes  \n",
      "13976                0                 1                 1                  0  \n",
      "42022                1                 0                 1                  0  \n",
      "17593                1                 0                 1                  0  \n",
      "24489                0                 1                 1                  0  \n",
      "44180                1                 0                 1                  0  \n",
      "\n",
      "[5 rows x 40 columns]\n",
      "            age  avg_yearly_balance  day  month  duration  campaign_contacts  \\\n",
      "40080  0.480519            0.901461    4      6 -0.401826           0.018519   \n",
      "44185  0.155844           -0.156036   15      7  0.168950           0.000000   \n",
      "8931   0.467532            1.859124    4      6  0.958904           0.018519   \n",
      "48056  0.337662            0.454798   11      3  0.027397           0.037037   \n",
      "49238  0.350649           -0.131632   28      8 -0.767123           0.037037   \n",
      "\n",
      "       prev_days  previous_contacts  in_default_no  in_default_yes  ...  \\\n",
      "40080        0.0           0.000000              1               0  ...   \n",
      "44185       92.0           0.017241              1               0  ...   \n",
      "8931         0.0           0.000000              1               0  ...   \n",
      "48056        0.0           0.000000              1               0  ...   \n",
      "49238        0.0           0.000000              1               0  ...   \n",
      "\n",
      "       contact_method_telephone  contact_method_unknown  prev_outcome_failure  \\\n",
      "40080                         0                       0                     0   \n",
      "44185                         0                       0                     0   \n",
      "8931                          0                       1                     0   \n",
      "48056                         0                       0                     0   \n",
      "49238                         0                       0                     0   \n",
      "\n",
      "       prev_outcome_other  prev_outcome_success  prev_outcome_unknown  \\\n",
      "40080                   0                     0                     1   \n",
      "44185                   0                     1                     0   \n",
      "8931                    0                     0                     1   \n",
      "48056                   0                     0                     1   \n",
      "49238                   0                     0                     1   \n",
      "\n",
      "       housing_loan_no  housing_loan_yes  personal_loan_no  personal_loan_yes  \n",
      "40080                1                 0                 1                  0  \n",
      "44185                1                 0                 1                  0  \n",
      "8931                 0                 1                 1                  0  \n",
      "48056                1                 0                 1                  0  \n",
      "49238                1                 0                 1                  0  \n",
      "\n",
      "[5 rows x 40 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "#preprocessing the data more appropriately for Random Forest\n",
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def preproc(dataframe, column, scalertype):\n",
    "    X = pd.DataFrame(dataframe[column])\n",
    "    scaler = scalertype.fit_transform(X)\n",
    "    dataframe[column] = scaler\n",
    "    \n",
    "df_X = df.drop(columns = ['term_deposit'])\n",
    "df_y = df['term_deposit']\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size = 0.3, random_state = 44)\n",
    "    \n",
    "preproc(X_train, 'avg_yearly_balance', RobustScaler())\n",
    "preproc(X_train, 'duration', RobustScaler())\n",
    "preproc(X_train, 'prev_days', RobustScaler())\n",
    "preproc(X_train, 'campaign_contacts', MinMaxScaler())\n",
    "preproc(X_train, 'previous_contacts', MinMaxScaler())\n",
    "preproc(X_train, 'age', MinMaxScaler())\n",
    "preproc(X_train, 'campaign_contacts', MinMaxScaler())\n",
    "\n",
    "preproc(X_test, 'avg_yearly_balance', RobustScaler())\n",
    "preproc(X_test, 'duration', RobustScaler())\n",
    "preproc(X_test, 'prev_days', RobustScaler())\n",
    "preproc(X_test, 'campaign_contacts', MinMaxScaler())\n",
    "preproc(X_test, 'previous_contacts', MinMaxScaler())\n",
    "preproc(X_test, 'age', MinMaxScaler())\n",
    "preproc(X_test, 'campaign_contacts', MinMaxScaler())\n",
    "\n",
    "print(X_train.head())\n",
    "print(X_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([2.29280210e+00, 2.21992842e+01, 1.11637063e+02, 2.05373411e+00,\n",
       "        1.97851687e+01, 9.92668643e+01, 3.26532054e+00, 3.26523731e+01,\n",
       "        1.70563412e+02, 2.93354092e+00, 2.95108131e+01, 1.76399547e+02,\n",
       "        3.66220646e+00, 3.77456754e+01, 2.06702899e+02, 3.29977460e+00,\n",
       "        3.12933166e+01, 1.89527430e+02, 1.05808115e-01, 5.56944036e-01,\n",
       "        2.40286708e+00, 9.04064178e-02, 4.54905653e-01, 2.23412180e+00]),\n",
       " 'std_fit_time': array([3.49387176e-02, 1.58803210e-01, 8.43251154e-01, 5.33834325e-02,\n",
       "        1.94614827e-01, 8.43974227e-01, 3.70868293e-02, 1.07618951e-01,\n",
       "        1.93966697e+00, 4.50822193e-02, 2.17414544e-01, 1.23209753e+01,\n",
       "        2.48357392e-01, 1.60015870e+00, 5.11908034e+00, 7.87045592e-02,\n",
       "        1.58064381e+00, 1.71407026e+01, 1.86714305e-02, 5.75463268e-02,\n",
       "        3.99556039e-01, 5.08327719e-03, 9.07982773e-03, 2.90850295e-01]),\n",
       " 'mean_score_time': array([ 0.0910058 ,  0.8281908 ,  4.5134872 ,  0.10421367,  0.84359283,\n",
       "         4.18532004,  0.13541126,  1.28069897,  7.23911896,  0.13548679,\n",
       "         1.29623137, 11.29413466,  0.15521431,  1.49418426, 18.37977834,\n",
       "         0.16183333,  1.54418459, 20.30968943,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " 'std_score_time': array([1.78907158e-03, 2.17798678e-02, 7.22493112e-01, 1.32413463e-02,\n",
       "        2.54896496e-02, 5.51381686e-02, 1.85071667e-03, 4.04630694e-02,\n",
       "        5.01066110e-01, 1.89835309e-03, 3.40713952e-02, 3.47101623e+00,\n",
       "        8.72827705e-03, 1.19734621e-01, 4.64446681e+00, 9.01653671e-03,\n",
       "        3.67517470e-01, 6.37915833e+00, 0.00000000e+00, 0.00000000e+00,\n",
       "        0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 0.00000000e+00]),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 30, 30,\n",
       "                    30, 30, 30, 30, 'None', 'None', 'None', 'None', 'None',\n",
       "                    'None'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'log2', 'log2', 'log2', 'auto',\n",
       "                    'auto', 'auto', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'auto', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
       "                    'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 1000, 5000, 100, 1000, 5000, 100, 1000, 5000, 100,\n",
       "                    1000, 5000, 100, 1000, 5000, 100, 1000, 5000, 100,\n",
       "                    1000, 5000, 100, 1000, 5000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 10, 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 10, 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 5000},\n",
       "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 5000},\n",
       "  {'max_depth': 30, 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 30, 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 30, 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 30, 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 30, 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 30, 'max_features': 'log2', 'n_estimators': 5000},\n",
       "  {'max_depth': 'None', 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 'None', 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 'None', 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 'None', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 'None', 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 'None', 'max_features': 'log2', 'n_estimators': 5000}],\n",
       " 'split0_test_score': array([0.90061755, 0.90061755, 0.9010484 , 0.899325  , 0.89717076,\n",
       "        0.89688353, 0.91426109, 0.91526641, 0.91584087, 0.91153239,\n",
       "        0.91210685, 0.91282493, 0.91426109, 0.91526641, 0.91641534,\n",
       "        0.9125377 , 0.9125377 , 0.91383025,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split1_test_score': array([0.89961224, 0.89817607, 0.89817607, 0.89745799, 0.89745799,\n",
       "        0.89702714, 0.91325578, 0.91196323, 0.91239408, 0.91124515,\n",
       "        0.911676  , 0.91110154, 0.91225047, 0.9125377 , 0.91354301,\n",
       "        0.90923453, 0.91023984, 0.91181962,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split2_test_score': array([0.89945418, 0.89974145, 0.89974145, 0.89844872, 0.89801781,\n",
       "        0.89816145, 0.91051422, 0.9123815 , 0.91094513, 0.90879058,\n",
       "        0.91008331, 0.90979604, 0.91166332, 0.91137604, 0.91137604,\n",
       "        0.90792876, 0.91080149, 0.91008331,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split3_test_score': array([0.90117782, 0.90045964, 0.90074691, 0.89887963, 0.89859236,\n",
       "        0.89902327, 0.91539787, 0.91338696, 0.91410514, 0.91410514,\n",
       "        0.91266877, 0.91381787, 0.91453605, 0.91381787, 0.91338696,\n",
       "        0.91309968, 0.91281241, 0.91439242,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split4_test_score': array([0.90002873, 0.90017236, 0.90017236, 0.89744326, 0.89729963,\n",
       "        0.89729963, 0.90879058, 0.91037058, 0.90950876, 0.90835967,\n",
       "        0.9096524 , 0.90907785, 0.91094513, 0.91108877, 0.91065786,\n",
       "        0.9085033 , 0.91008331, 0.9096524 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'mean_test_score': array([0.9001781 , 0.89983342, 0.89997704, 0.89831092, 0.89770771,\n",
       "        0.897679  , 0.91244391, 0.91267374, 0.9125588 , 0.91080658,\n",
       "        0.91123747, 0.91132364, 0.91273121, 0.91281736, 0.91307584,\n",
       "        0.91026079, 0.91129495, 0.9119556 ,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'std_test_score': array([0.00064174, 0.00088058, 0.00100773, 0.00075513, 0.00052839,\n",
       "        0.00080516, 0.00243958, 0.00162021, 0.0022404 , 0.00208093,\n",
       "        0.00116973, 0.00178334, 0.00142545, 0.00155836, 0.00201014,\n",
       "        0.00213654, 0.00115516, 0.00191212,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'rank_test_score': array([13, 15, 14, 16, 17, 18,  6,  4,  5, 11, 10,  8,  3,  2,  1, 12,  9,\n",
       "         7, 19, 20, 21, 22, 23, 24])}"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "parameter_grid = {'n_estimators' : [100,1000,5000], 'max_depth' : [10, 20, 30, 'None'], 'max_features' : ['auto', 'log2']}\n",
    "rfc = RandomForestClassifier()\n",
    "grid = GridSearchCV(estimator = rfc, param_grid = parameter_grid, scoring = 'accuracy').fit(X_train, y_train)\n",
    "grid.best_params_\n",
    "grid.cv_results_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'max_features': 'auto', 'n_estimators': 5000}"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 1.0, Test Score: 0.9154155495978552 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.95     13107\n",
      "         yes       0.76      0.45      0.56      1813\n",
      "\n",
      "    accuracy                           0.92     14920\n",
      "   macro avg       0.84      0.71      0.76     14920\n",
      "weighted avg       0.91      0.92      0.91     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfc_best = RandomForestClassifier(max_depth = 30, max_features = 'auto', n_estimators = 5000)\n",
    "rfc_best.fit(X_train, y_train)\n",
    "rfc_predictions = rfc_best.predict(X_test)\n",
    "rfc_train_score = rfc_best.score(X_train, y_train)\n",
    "rfc_test_score = rfc_best.score(X_test, y_test)\n",
    "print(\"Train Score: {}, Test Score: {} \\n\".format(rfc_train_score, rfc_test_score))\n",
    "print(\"\\n{}\".format(classification_report(y_test, rfc_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this model is based on the choice to achieve accuracy. We are going to run the grid search again to get recall this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n",
      "C:\\Users\\elyse\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "TypeError: '<=' not supported between instances of 'str' and 'int'\n",
      "\n",
      "  FitFailedWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mean_fit_time': array([4.14125676e+00, 5.13492275e+01, 2.38762646e+02, 6.44557505e+00,\n",
       "        5.58033402e+01, 2.16808331e+02, 7.38903651e+00, 6.01195673e+01,\n",
       "        3.20777254e+02, 5.61252470e+00, 5.82573845e+01, 3.09918411e+02,\n",
       "        7.72016196e+00, 6.33442125e+01, 3.46368264e+02, 5.78050666e+00,\n",
       "        6.02209462e+01, 3.28284658e+02, 1.29809809e-01, 4.62342882e-01,\n",
       "        2.05601168e+00, 1.00510979e-01, 5.79252529e-01, 2.03242617e+00]),\n",
       " 'std_fit_time': array([4.59233312e-01, 3.96030132e+00, 9.84496837e+00, 1.60162490e+00,\n",
       "        1.27916885e+01, 9.77332525e+00, 1.74162798e+00, 1.24604803e+00,\n",
       "        9.15850527e+00, 8.92500636e-02, 1.43563466e+00, 8.85700449e+00,\n",
       "        1.57831049e+00, 1.36232510e+00, 5.36978140e+00, 3.98901209e-02,\n",
       "        2.68621709e+00, 4.91308847e+00, 3.49675970e-02, 7.71641552e-03,\n",
       "        4.23545497e-02, 1.06208813e-02, 2.56012455e-01, 4.34086486e-02]),\n",
       " 'mean_score_time': array([ 0.25541883,  2.70506988, 19.49194713,  0.34648719,  2.77940307,\n",
       "        18.46979971,  0.3320291 ,  3.05916686, 18.44407263,  0.30823412,\n",
       "         3.15983052, 19.35173101,  0.36032391,  3.15352039, 25.76310635,\n",
       "         0.33403363,  3.26594615, 29.30940747,  0.        ,  0.        ,\n",
       "         0.        ,  0.        ,  0.        ,  0.        ]),\n",
       " 'std_score_time': array([0.04093509, 0.62163281, 2.10973109, 0.08830461, 0.42773495,\n",
       "        3.02883778, 0.06966154, 0.24668574, 3.24215333, 0.0633374 ,\n",
       "        0.27964116, 1.4870129 , 0.05625072, 0.06423114, 3.21983096,\n",
       "        0.02303575, 0.12517494, 3.41996732, 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        ]),\n",
       " 'param_max_depth': masked_array(data=[10, 10, 10, 10, 10, 10, 20, 20, 20, 20, 20, 20, 30, 30,\n",
       "                    30, 30, 30, 30, 'None', 'None', 'None', 'None', 'None',\n",
       "                    'None'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_max_features': masked_array(data=['auto', 'auto', 'auto', 'log2', 'log2', 'log2', 'auto',\n",
       "                    'auto', 'auto', 'log2', 'log2', 'log2', 'auto', 'auto',\n",
       "                    'auto', 'log2', 'log2', 'log2', 'auto', 'auto', 'auto',\n",
       "                    'log2', 'log2', 'log2'],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'param_n_estimators': masked_array(data=[100, 1000, 5000, 100, 1000, 5000, 100, 1000, 5000, 100,\n",
       "                    1000, 5000, 100, 1000, 5000, 100, 1000, 5000, 100,\n",
       "                    1000, 5000, 100, 1000, 5000],\n",
       "              mask=[False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False,\n",
       "                    False, False, False, False, False, False, False, False],\n",
       "        fill_value='?',\n",
       "             dtype=object),\n",
       " 'params': [{'max_depth': 10, 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 10, 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 10, 'max_features': 'log2', 'n_estimators': 5000},\n",
       "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 20, 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 20, 'max_features': 'log2', 'n_estimators': 5000},\n",
       "  {'max_depth': 30, 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 30, 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 30, 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 30, 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 30, 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 30, 'max_features': 'log2', 'n_estimators': 5000},\n",
       "  {'max_depth': 'None', 'max_features': 'auto', 'n_estimators': 100},\n",
       "  {'max_depth': 'None', 'max_features': 'auto', 'n_estimators': 1000},\n",
       "  {'max_depth': 'None', 'max_features': 'auto', 'n_estimators': 5000},\n",
       "  {'max_depth': 'None', 'max_features': 'log2', 'n_estimators': 100},\n",
       "  {'max_depth': 'None', 'max_features': 'log2', 'n_estimators': 1000},\n",
       "  {'max_depth': 'None', 'max_features': 'log2', 'n_estimators': 5000}],\n",
       " 'split0_test_score': array([0.2125 , 0.1975 , 0.20125, 0.1675 , 0.155  , 0.1625 , 0.42125,\n",
       "        0.41   , 0.4175 , 0.3875 , 0.38625, 0.38125, 0.41125, 0.435  ,\n",
       "        0.435  , 0.39   , 0.4025 , 0.40625,     nan,     nan,     nan,\n",
       "            nan,     nan,     nan]),\n",
       " 'split1_test_score': array([0.18875, 0.1775 , 0.1725 , 0.1575 , 0.155  , 0.15125, 0.40125,\n",
       "        0.3975 , 0.3975 , 0.37   , 0.37125, 0.36375, 0.41625, 0.41375,\n",
       "        0.41375, 0.38375, 0.3825 , 0.38125,     nan,     nan,     nan,\n",
       "            nan,     nan,     nan]),\n",
       " 'split2_test_score': array([0.19148936, 0.19399249, 0.19649562, 0.1689612 , 0.17146433,\n",
       "        0.16770964, 0.37797247, 0.38423029, 0.38423029, 0.35294118,\n",
       "        0.35669587, 0.35544431, 0.38172716, 0.39299124, 0.39674593,\n",
       "        0.37546934, 0.36545682, 0.37046308,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split3_test_score': array([0.2077597 , 0.19774718, 0.19274093, 0.17647059, 0.16520651,\n",
       "        0.1689612 , 0.40926158, 0.40926158, 0.40425532, 0.3767209 ,\n",
       "        0.37797247, 0.37546934, 0.40801001, 0.4155194 , 0.41176471,\n",
       "        0.38798498, 0.39299124, 0.39674593,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'split4_test_score': array([0.18523154, 0.18773467, 0.19399249, 0.17396746, 0.16145181,\n",
       "        0.16020025, 0.3979975 , 0.38548185, 0.38923655, 0.35544431,\n",
       "        0.35794743, 0.359199  , 0.40300375, 0.38297872, 0.3942428 ,\n",
       "        0.37171464, 0.37546934, 0.37171464,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'mean_test_score': array([0.19714612, 0.19089487, 0.19139581, 0.16887985, 0.16162453,\n",
       "        0.16212422, 0.40154631, 0.39729474, 0.39854443, 0.36852128,\n",
       "        0.37002315, 0.36702253, 0.40404819, 0.40804787, 0.41030069,\n",
       "        0.38178379, 0.38378348, 0.38528473,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'std_test_score': array([0.0108889 , 0.00761034, 0.00988652, 0.00655614, 0.00628412,\n",
       "        0.00632507, 0.01425601, 0.01108959, 0.01170086, 0.01298737,\n",
       "        0.01141444, 0.00979532, 0.01196466, 0.01827523, 0.01459921,\n",
       "        0.00708642, 0.01297482, 0.01407842,        nan,        nan,\n",
       "               nan,        nan,        nan,        nan]),\n",
       " 'rank_test_score': array([13, 15, 14, 16, 18, 17,  4,  6,  5, 11, 10, 12,  3,  2,  1,  9,  8,\n",
       "         7, 19, 20, 21, 22, 23, 24])}"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_re = GridSearchCV(estimator = rfc, param_grid = parameter_grid, scoring = 'recall').fit(X_train, y_train == 'yes')\n",
    "grid_re.best_params_\n",
    "grid_re.cv_results_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 30, 'max_features': 'auto', 'n_estimators': 5000}"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_re.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well it's reassuring to see that the original model went ahead and ended on the same best parameters. it's time to tweak the data a bit, like before. I want to be able to have the highest recall possible, but this time, seeing if we can't increase our accuracy while we do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Threshold: 0.01. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57     13107\n",
      "           1       0.19      1.00      0.31      1813\n",
      "\n",
      "    accuracy                           0.47     14920\n",
      "   macro avg       0.59      0.70      0.44     14920\n",
      "weighted avg       0.90      0.47      0.54     14920\n",
      "\n",
      "Probability Threshold: 0.025. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.57      0.72     13107\n",
      "           1       0.24      0.99      0.39      1813\n",
      "\n",
      "    accuracy                           0.62     14920\n",
      "   macro avg       0.62      0.78      0.56     14920\n",
      "weighted avg       0.91      0.62      0.68     14920\n",
      "\n",
      "Probability Threshold: 0.05. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.81     13107\n",
      "           1       0.30      0.98      0.46      1813\n",
      "\n",
      "    accuracy                           0.72     14920\n",
      "   macro avg       0.65      0.83      0.64     14920\n",
      "weighted avg       0.91      0.72      0.77     14920\n",
      "\n",
      "Probability Threshold: 0.075. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.86     13107\n",
      "           1       0.35      0.96      0.52      1813\n",
      "\n",
      "    accuracy                           0.78     14920\n",
      "   macro avg       0.67      0.86      0.69     14920\n",
      "weighted avg       0.92      0.78      0.82     14920\n",
      "\n",
      "Probability Threshold: 0.1. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     13107\n",
      "           1       0.39      0.95      0.55      1813\n",
      "\n",
      "    accuracy                           0.81     14920\n",
      "   macro avg       0.69      0.87      0.72     14920\n",
      "weighted avg       0.92      0.81      0.84     14920\n",
      "\n",
      "Probability Threshold: 0.15. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91     13107\n",
      "           1       0.45      0.90      0.60      1813\n",
      "\n",
      "    accuracy                           0.85     14920\n",
      "   macro avg       0.72      0.87      0.75     14920\n",
      "weighted avg       0.92      0.85      0.87     14920\n",
      "\n",
      "Probability Threshold: 0.2. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.88      0.93     13107\n",
      "           1       0.51      0.86      0.64      1813\n",
      "\n",
      "    accuracy                           0.88     14920\n",
      "   macro avg       0.74      0.87      0.78     14920\n",
      "weighted avg       0.92      0.88      0.89     14920\n",
      "\n",
      "Probability Threshold: 0.25. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94     13107\n",
      "           1       0.55      0.81      0.66      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.76      0.86      0.80     14920\n",
      "weighted avg       0.92      0.90      0.91     14920\n",
      "\n",
      "Probability Threshold: 0.3. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95     13107\n",
      "           1       0.60      0.75      0.67      1813\n",
      "\n",
      "    accuracy                           0.91     14920\n",
      "   macro avg       0.78      0.84      0.81     14920\n",
      "weighted avg       0.92      0.91      0.91     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "proba_thresh_list = [0.01, 0.025, 0.05,0.075,0.1,0.15,0.2,0.25,0.3]\n",
    "rfc_best_proba = rfc_best.predict_proba(X_test)\n",
    "for i in proba_thresh_list:\n",
    "    rfc_best_lower_thresh = (rfc_best_proba[:,1] >i).astype('int')\n",
    "    print(\"Probability Threshold: {}. \\n{}\".format(i, classification_report((y_test == 'yes').astype('int'), rfc_best_lower_thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability Threshold: 0.01. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.57     13107\n",
      "           1       0.19      1.00      0.31      1813\n",
      "\n",
      "    accuracy                           0.47     14920\n",
      "   macro avg       0.59      0.70      0.44     14920\n",
      "weighted avg       0.90      0.47      0.54     14920\n",
      "\n",
      "Probability Threshold: 0.011. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59     13107\n",
      "           1       0.19      1.00      0.32      1813\n",
      "\n",
      "    accuracy                           0.49     14920\n",
      "   macro avg       0.60      0.71      0.46     14920\n",
      "weighted avg       0.90      0.49      0.56     14920\n",
      "\n",
      "Probability Threshold: 0.011999999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.43      0.60     13107\n",
      "           1       0.20      1.00      0.33      1813\n",
      "\n",
      "    accuracy                           0.50     14920\n",
      "   macro avg       0.60      0.72      0.47     14920\n",
      "weighted avg       0.90      0.50      0.57     14920\n",
      "\n",
      "Probability Threshold: 0.012999999999999998. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62     13107\n",
      "           1       0.20      1.00      0.33      1813\n",
      "\n",
      "    accuracy                           0.51     14920\n",
      "   macro avg       0.60      0.72      0.48     14920\n",
      "weighted avg       0.90      0.51      0.58     14920\n",
      "\n",
      "Probability Threshold: 0.013999999999999997. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63     13107\n",
      "           1       0.20      1.00      0.34      1813\n",
      "\n",
      "    accuracy                           0.53     14920\n",
      "   macro avg       0.60      0.73      0.49     14920\n",
      "weighted avg       0.90      0.53      0.60     14920\n",
      "\n",
      "Probability Threshold: 0.014999999999999996. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.47      0.64     13107\n",
      "           1       0.21      1.00      0.34      1813\n",
      "\n",
      "    accuracy                           0.54     14920\n",
      "   macro avg       0.60      0.74      0.49     14920\n",
      "weighted avg       0.90      0.54      0.61     14920\n",
      "\n",
      "Probability Threshold: 0.015999999999999993. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.49      0.65     13107\n",
      "           1       0.21      1.00      0.35      1813\n",
      "\n",
      "    accuracy                           0.55     14920\n",
      "   macro avg       0.60      0.74      0.50     14920\n",
      "weighted avg       0.90      0.55      0.62     14920\n",
      "\n",
      "Probability Threshold: 0.016999999999999994. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.66     13107\n",
      "           1       0.21      1.00      0.35      1813\n",
      "\n",
      "    accuracy                           0.56     14920\n",
      "   macro avg       0.61      0.75      0.51     14920\n",
      "weighted avg       0.90      0.56      0.63     14920\n",
      "\n",
      "Probability Threshold: 0.017999999999999995. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.51      0.67     13107\n",
      "           1       0.22      1.00      0.36      1813\n",
      "\n",
      "    accuracy                           0.57     14920\n",
      "   macro avg       0.61      0.75      0.52     14920\n",
      "weighted avg       0.90      0.57      0.64     14920\n",
      "\n",
      "Probability Threshold: 0.018999999999999993. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.52      0.68     13107\n",
      "           1       0.22      0.99      0.36      1813\n",
      "\n",
      "    accuracy                           0.58     14920\n",
      "   macro avg       0.61      0.76      0.52     14920\n",
      "weighted avg       0.90      0.58      0.64     14920\n",
      "\n",
      "Probability Threshold: 0.01999999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.53      0.69     13107\n",
      "           1       0.23      0.99      0.37      1813\n",
      "\n",
      "    accuracy                           0.58     14920\n",
      "   macro avg       0.61      0.76      0.53     14920\n",
      "weighted avg       0.90      0.58      0.65     14920\n",
      "\n",
      "Probability Threshold: 0.02099999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.54      0.70     13107\n",
      "           1       0.23      0.99      0.37      1813\n",
      "\n",
      "    accuracy                           0.59     14920\n",
      "   macro avg       0.61      0.77      0.54     14920\n",
      "weighted avg       0.91      0.59      0.66     14920\n",
      "\n",
      "Probability Threshold: 0.021999999999999992. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71     13107\n",
      "           1       0.23      0.99      0.38      1813\n",
      "\n",
      "    accuracy                           0.60     14920\n",
      "   macro avg       0.62      0.77      0.54     14920\n",
      "weighted avg       0.91      0.60      0.67     14920\n",
      "\n",
      "Probability Threshold: 0.02299999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.55      0.71     13107\n",
      "           1       0.24      0.99      0.38      1813\n",
      "\n",
      "    accuracy                           0.61     14920\n",
      "   macro avg       0.62      0.77      0.55     14920\n",
      "weighted avg       0.91      0.61      0.67     14920\n",
      "\n",
      "Probability Threshold: 0.023999999999999987. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.56      0.72     13107\n",
      "           1       0.24      0.99      0.38      1813\n",
      "\n",
      "    accuracy                           0.61     14920\n",
      "   macro avg       0.62      0.78      0.55     14920\n",
      "weighted avg       0.91      0.61      0.68     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#This model does perform noticeably better than the previous rfc model. Let's go ahead and get to the nitty details\n",
    "for i in np.arange(0.01, 0.025, 0.001): \n",
    "    rfc_best_lower_thresh = (rfc_best_proba[:,1] >i).astype('int')\n",
    "    print(\"Probability Threshold: {}. \\n{}\".format(i, classification_report((y_test == 'yes').astype('int'), rfc_best_lower_thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1.8% revised\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5840.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 114145.45\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 19.55\n",
      "\n",
      "Threshold: 1.8% old\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5840.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 132168.42\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 22.63\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Still have the same breaking point at 1.8%, but here we have a higher precision of .22 vs .19, which is going to save a many calls\n",
    "#bringing in the tradeoff report\n",
    "def trade_off_report(rf_tuple, cust = 50000, conv_perc = 0.1168, avg_dur = 4.3):\n",
    "    nm_conv = round((cust * conv_perc),2)\n",
    "    nm_dur_total = round((cust * avg_dur),2)\n",
    "    nm_conv_interval = round((nm_dur_total / nm_conv),2)\n",
    "    m_conv = round((nm_conv * rf_tuple[2]),2)\n",
    "    m_dur_total = round(((m_conv / rf_tuple[1]) * avg_dur),2) #getting all customers that would be called for 'yes', then multiplying by duration\n",
    "    m_conv_interval = round((m_dur_total / m_conv),2)\n",
    "    print(\"Threshold: {}\\nNo Model Conversions: {}\\nModel Conversions: {}\\nNo Model Minutes used: {}\\nModel Minutes Used: {}\\n\\\n",
    "    No Model Conversion Interval: {}\\nModel Conversion Interval: {}\\n\".format(rf_tuple[0], nm_conv, m_conv, nm_dur_total, m_dur_total, nm_conv_interval, m_conv_interval))\n",
    "\n",
    "rf_018 = (\"1.8% revised\", 0.22, 1.0)\n",
    "rf_018_old = ('1.8% old', 0.19, 1.0)\n",
    "\n",
    "trade_off_report(rf_018)\n",
    "trade_off_report(rf_018_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Revised additional minute savings = 18022.970000000016\n"
     ]
    }
   ],
   "source": [
    "print(\"Revised additional minute savings = \" + str(132168.42 - 114145.45))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So this is at our best recall. But, the company may be interested in more focused iterations. So let's go ahead and run a few more trade_off_reports\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1.8%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5840.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 114145.45\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 19.55\n",
      "\n",
      "Threshold: 5%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5723.2\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 82032.53\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 14.33\n",
      "\n",
      "Threshold: 10%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5548.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 61170.26\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 11.03\n",
      "\n",
      "Threshold: 15%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5256.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 50224.0\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 9.56\n",
      "\n",
      "Threshold: 20%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5022.4\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 42345.73\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 8.43\n",
      "\n",
      "Threshold: 25%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 4730.4\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 36983.13\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 7.82\n",
      "\n",
      "Threshold: 30%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 4380.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 31390.0\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 7.17\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_018 = (\"1.8%\", 0.22, 1.0)\n",
    "rf_05 = ('5%', 0.3, 0.98)\n",
    "rf_10 = ('10%', 0.39, 0.95)\n",
    "rf_15 = ('15%', 0.45, 0.9)\n",
    "rf_20 = ('20%', 0.51, 0.86)\n",
    "rf_25 = ('25%', 0.55, 0.81)\n",
    "rf_30 = ('30%', 0.6, 0.75)\n",
    "\n",
    "tuple_list = [rf_018, rf_05,rf_10, rf_15, rf_20, rf_25, rf_30]\n",
    "for i in tuple_list:\n",
    "    trade_off_report(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While this view is approachable. It still lacks priority. Here we can see that if we were to simply run everybody through a specific threshold we can do a single split of customers to reduce our time. But we can actively seek prioritization through tiering the customers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(49732, 40)\n",
      "(49732,)\n"
     ]
    }
   ],
   "source": [
    "X_whole = pd.concat([X_train, X_test])\n",
    "print(X_whole.shape)\n",
    "y_whole = pd.concat([y_train, y_test])\n",
    "print(y_whole.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>in_default_no</th>\n",
       "      <th>in_default_yes</th>\n",
       "      <th>...</th>\n",
       "      <th>contact_method_unknown</th>\n",
       "      <th>prev_outcome_failure</th>\n",
       "      <th>prev_outcome_other</th>\n",
       "      <th>prev_outcome_success</th>\n",
       "      <th>prev_outcome_unknown</th>\n",
       "      <th>housing_loan_no</th>\n",
       "      <th>housing_loan_yes</th>\n",
       "      <th>personal_loan_no</th>\n",
       "      <th>personal_loan_yes</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13976</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>-0.127183</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42022</th>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.208785</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.177908</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.314815</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24489</th>\n",
       "      <td>0.350649</td>\n",
       "      <td>1.153464</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.546296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44180</th>\n",
       "      <td>0.155844</td>\n",
       "      <td>-0.168351</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  avg_yearly_balance  day  month  duration  campaign_contacts  \\\n",
       "13976  0.363636           -0.127183   10      7  0.023148           0.000000   \n",
       "42022  0.467532            0.208785   28     10  0.555556           0.000000   \n",
       "17593  0.428571           -0.177908   29      7 -0.314815           0.016129   \n",
       "24489  0.350649            1.153464   17     11 -0.546296           0.000000   \n",
       "44180  0.155844           -0.168351   14      7  0.754630           0.129032   \n",
       "\n",
       "       prev_days  previous_contacts  in_default_no  in_default_yes  ...  \\\n",
       "13976        0.0           0.000000              1               0  ...   \n",
       "42022        0.0           0.000000              1               0  ...   \n",
       "17593        0.0           0.000000              1               0  ...   \n",
       "24489      132.0           0.003636              1               0  ...   \n",
       "44180        0.0           0.000000              1               0  ...   \n",
       "\n",
       "       contact_method_unknown  prev_outcome_failure  prev_outcome_other  \\\n",
       "13976                       0                     0                   0   \n",
       "42022                       0                     0                   0   \n",
       "17593                       0                     0                   0   \n",
       "24489                       0                     1                   0   \n",
       "44180                       0                     0                   0   \n",
       "\n",
       "       prev_outcome_success  prev_outcome_unknown  housing_loan_no  \\\n",
       "13976                     0                     1                0   \n",
       "42022                     0                     1                1   \n",
       "17593                     0                     1                1   \n",
       "24489                     0                     0                0   \n",
       "44180                     0                     1                1   \n",
       "\n",
       "       housing_loan_yes  personal_loan_no  personal_loan_yes  probability  \n",
       "13976                 1                 1                  0        0.001  \n",
       "42022                 0                 1                  0        0.140  \n",
       "17593                 0                 1                  0        0.003  \n",
       "24489                 1                 1                  0        0.001  \n",
       "44180                 0                 1                  0        0.040  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_whole_proba = rfc_best.predict_proba(X_whole)\n",
    "X_whole['probability'] = rfc_whole_proba[:,1]\n",
    "X_whole['probability'] = X_whole['probability'].round(3)\n",
    "X_whole.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>in_default_no</th>\n",
       "      <th>in_default_yes</th>\n",
       "      <th>...</th>\n",
       "      <th>prev_outcome_other</th>\n",
       "      <th>prev_outcome_success</th>\n",
       "      <th>prev_outcome_unknown</th>\n",
       "      <th>housing_loan_no</th>\n",
       "      <th>housing_loan_yes</th>\n",
       "      <th>personal_loan_no</th>\n",
       "      <th>personal_loan_yes</th>\n",
       "      <th>probability</th>\n",
       "      <th>tier</th>\n",
       "      <th>term_deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13976</th>\n",
       "      <td>0.363636</td>\n",
       "      <td>-0.127183</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.023148</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tier_4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42022</th>\n",
       "      <td>0.467532</td>\n",
       "      <td>0.208785</td>\n",
       "      <td>28</td>\n",
       "      <td>10</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.140</td>\n",
       "      <td>tier_3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17593</th>\n",
       "      <td>0.428571</td>\n",
       "      <td>-0.177908</td>\n",
       "      <td>29</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.314815</td>\n",
       "      <td>0.016129</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.003</td>\n",
       "      <td>tier_4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24489</th>\n",
       "      <td>0.350649</td>\n",
       "      <td>1.153464</td>\n",
       "      <td>17</td>\n",
       "      <td>11</td>\n",
       "      <td>-0.546296</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.003636</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001</td>\n",
       "      <td>tier_4</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44180</th>\n",
       "      <td>0.155844</td>\n",
       "      <td>-0.168351</td>\n",
       "      <td>14</td>\n",
       "      <td>7</td>\n",
       "      <td>0.754630</td>\n",
       "      <td>0.129032</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.040</td>\n",
       "      <td>tier_3</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            age  avg_yearly_balance  day  month  duration  campaign_contacts  \\\n",
       "13976  0.363636           -0.127183   10      7  0.023148           0.000000   \n",
       "42022  0.467532            0.208785   28     10  0.555556           0.000000   \n",
       "17593  0.428571           -0.177908   29      7 -0.314815           0.016129   \n",
       "24489  0.350649            1.153464   17     11 -0.546296           0.000000   \n",
       "44180  0.155844           -0.168351   14      7  0.754630           0.129032   \n",
       "\n",
       "       prev_days  previous_contacts  in_default_no  in_default_yes  ...  \\\n",
       "13976        0.0           0.000000              1               0  ...   \n",
       "42022        0.0           0.000000              1               0  ...   \n",
       "17593        0.0           0.000000              1               0  ...   \n",
       "24489      132.0           0.003636              1               0  ...   \n",
       "44180        0.0           0.000000              1               0  ...   \n",
       "\n",
       "       prev_outcome_other  prev_outcome_success  prev_outcome_unknown  \\\n",
       "13976                   0                     0                     1   \n",
       "42022                   0                     0                     1   \n",
       "17593                   0                     0                     1   \n",
       "24489                   0                     0                     0   \n",
       "44180                   0                     0                     1   \n",
       "\n",
       "       housing_loan_no  housing_loan_yes  personal_loan_no  personal_loan_yes  \\\n",
       "13976                0                 1                 1                  0   \n",
       "42022                1                 0                 1                  0   \n",
       "17593                1                 0                 1                  0   \n",
       "24489                0                 1                 1                  0   \n",
       "44180                1                 0                 1                  0   \n",
       "\n",
       "       probability    tier  term_deposit  \n",
       "13976        0.001  tier_4            no  \n",
       "42022        0.140  tier_3            no  \n",
       "17593        0.003  tier_4            no  \n",
       "24489        0.001  tier_4            no  \n",
       "44180        0.040  tier_3            no  \n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_whole['tier'] = pd.cut(X_whole['probability'],[0, 0.018, 0.4, 0.6, 1.0],labels=['tier_4', 'tier_3', 'tier_2', 'tier_1'])\n",
    "df_tiered = X_whole.copy()\n",
    "df_tiered['term_deposit'] = y_whole\n",
    "df_tiered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tier_4       9\n",
       "tier_3     681\n",
       "tier_2     584\n",
       "tier_1    4536\n",
       "Name: tier, dtype: int64"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiered.tier.loc[df_tiered['term_deposit'] == 'yes'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tier_4    24819\n",
       "tier_3    14903\n",
       "tier_2      417\n",
       "tier_1      107\n",
       "Name: tier, dtype: int64"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiered.tier.loc[df_tiered['term_deposit'] == 'no'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier 4: 0.0004\n",
      "Tier 3: 0.0437\n",
      "Tier 2: 0.5834\n",
      "Tier 1: 0.977\n"
     ]
    }
   ],
   "source": [
    "print(\"Tier 4: \" + str(round((9/24828),4)))\n",
    "print(\"Tier 3: \" + str(round((681/15584),4)))\n",
    "print(\"Tier 2: \" + str(round((584/1001),4)))\n",
    "print(\"Tier 1: \" + str(round((4536/4643),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compared to the previous model, this has higher probabiltiy accuracy and therfore a stronger tier 1, with less customers in the tier 2 and 3 sections and the vast majority in tier 4. Here we actually see a weird change where the tier 3 customers have more actual conversions than tier 2, but the proportion is much smaller compared to the tier 2.\n",
    "\n",
    "With this new campaign set up the company will be able to prioritize customers using this model as well as immensely cut down on the hours used if chosen to move forward with it. I believe this is better than near blind outgoing calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
