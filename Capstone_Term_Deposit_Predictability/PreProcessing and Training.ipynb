{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>in_default</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>personal_loan</th>\n",
       "      <th>contact_method</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>prev_outcome</th>\n",
       "      <th>term_deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education in_default  avg_yearly_balance  \\\n",
       "0   58    management  married   tertiary         no                2143   \n",
       "1   44    technician   single  secondary         no                  29   \n",
       "2   33  entrepreneur  married  secondary         no                   2   \n",
       "3   47   blue-collar  married    unknown         no                1506   \n",
       "4   33       unknown   single    unknown         no                   1   \n",
       "\n",
       "  housing_loan personal_loan contact_method  day  month  duration  \\\n",
       "0          yes            no        unknown    5      5       261   \n",
       "1          yes            no        unknown    5      5       151   \n",
       "2          yes           yes        unknown    5      5        76   \n",
       "3          yes            no        unknown    5      5        92   \n",
       "4           no            no        unknown    5      5       198   \n",
       "\n",
       "   campaign_contacts  prev_days  previous_contacts prev_outcome term_deposit  \n",
       "0                  1         -1                  0      unknown           no  \n",
       "1                  1         -1                  0      unknown           no  \n",
       "2                  1         -1                  0      unknown           no  \n",
       "3                  1         -1                  0      unknown           no  \n",
       "4                  1         -1                  0      unknown           no  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the cleaned dataframe for preprocessing\n",
    "\n",
    "df = pd.read_csv('Peruvian_Bank_Data/clean_df.csv', header = 0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I believe the best way to preprocess this is to provide dummy labels to the categorical data and then use a RobustScaler for avg_yearly_balance, and duration because of the outliers. Prev_days will also get a robustscaling, but this will be done last because it is subject to change -- I'm concerned about the negative one being abrasive to the model. But we will see.  MinMax scaler for campaign_contacts and previous_contacts and age. Let's begin and see how it goes. I will do the scaling first and then the dummy variables -- the dummy variables make the dataframe a bit unbearable to scroll through. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applying robustscaler to avg_yearly_balance, duration, prev_days\n",
    "X = pd.DataFrame(df['avg_yearly_balance'])\n",
    "RobSca = RobustScaler().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.copy() #creating a copy just in case something goes wrong\n",
    "#going off to replace the avg_yearly_balance values\n",
    "df2['avg_yearly_balance'] = RobSca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>in_default</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>personal_loan</th>\n",
       "      <th>contact_method</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>prev_outcome</th>\n",
       "      <th>term_deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1.247241</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.308315</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.328182</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.778514</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.328918</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education in_default  avg_yearly_balance  \\\n",
       "0   58    management  married   tertiary         no            1.247241   \n",
       "1   44    technician   single  secondary         no           -0.308315   \n",
       "2   33  entrepreneur  married  secondary         no           -0.328182   \n",
       "3   47   blue-collar  married    unknown         no            0.778514   \n",
       "4   33       unknown   single    unknown         no           -0.328918   \n",
       "\n",
       "  housing_loan personal_loan contact_method  day  month  duration  \\\n",
       "0          yes            no        unknown    5      5       261   \n",
       "1          yes            no        unknown    5      5       151   \n",
       "2          yes           yes        unknown    5      5        76   \n",
       "3          yes            no        unknown    5      5        92   \n",
       "4           no            no        unknown    5      5       198   \n",
       "\n",
       "   campaign_contacts  prev_days  previous_contacts prev_outcome term_deposit  \n",
       "0                  1         -1                  0      unknown           no  \n",
       "1                  1         -1                  0      unknown           no  \n",
       "2                  1         -1                  0      unknown           no  \n",
       "3                  1         -1                  0      unknown           no  \n",
       "4                  1         -1                  0      unknown           no  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.head() #looks successful, let's continue. As practice let's create a function for the remaining required preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a function to make the rest of the preprocessing simpler\n",
    "def preproc(dataframe, column, scalertype):\n",
    "    X = pd.DataFrame(dataframe[column])\n",
    "    scaler = scalertype.fit_transform(X)\n",
    "    dataframe[column] = scaler\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc(df2, 'duration', RobustScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "preproc(df2, 'prev_days', RobustScaler())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>in_default</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>personal_loan</th>\n",
       "      <th>contact_method</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>prev_outcome</th>\n",
       "      <th>term_deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519481</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1.247241</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.373272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337662</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.308315</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.133641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.328182</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.479263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.376623</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.778514</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.405530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.328918</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age           job  marital  education in_default  avg_yearly_balance  \\\n",
       "0  0.519481    management  married   tertiary         no            1.247241   \n",
       "1  0.337662    technician   single  secondary         no           -0.308315   \n",
       "2  0.194805  entrepreneur  married  secondary         no           -0.328182   \n",
       "3  0.376623   blue-collar  married    unknown         no            0.778514   \n",
       "4  0.194805       unknown   single    unknown         no           -0.328918   \n",
       "\n",
       "  housing_loan personal_loan contact_method  day  month  duration  \\\n",
       "0          yes            no        unknown    5      5  0.373272   \n",
       "1          yes            no        unknown    5      5 -0.133641   \n",
       "2          yes           yes        unknown    5      5 -0.479263   \n",
       "3          yes            no        unknown    5      5 -0.405530   \n",
       "4           no            no        unknown    5      5  0.082949   \n",
       "\n",
       "   campaign_contacts  prev_days  previous_contacts prev_outcome term_deposit  \n",
       "0                0.0        0.0                0.0      unknown           no  \n",
       "1                0.0        0.0                0.0      unknown           no  \n",
       "2                0.0        0.0                0.0      unknown           no  \n",
       "3                0.0        0.0                0.0      unknown           no  \n",
       "4                0.0        0.0                0.0      unknown           no  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#minmax for campaign_contacts and previous_contacts and age\n",
    "preproc(df2, 'campaign_contacts', MinMaxScaler())\n",
    "preproc(df2, 'previous_contacts', MinMaxScaler())\n",
    "preproc(df2, 'age', MinMaxScaler())\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>in_default</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>personal_loan</th>\n",
       "      <th>contact_method</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>prev_outcome</th>\n",
       "      <th>term_deposit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.519481</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1.247241</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.373272</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.337662</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.308315</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.133641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.328182</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.479263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.376623</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.778514</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.405530</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194805</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>-0.328918</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        age           job  marital  education in_default  avg_yearly_balance  \\\n",
       "0  0.519481    management  married   tertiary         no            1.247241   \n",
       "1  0.337662    technician   single  secondary         no           -0.308315   \n",
       "2  0.194805  entrepreneur  married  secondary         no           -0.328182   \n",
       "3  0.376623   blue-collar  married    unknown         no            0.778514   \n",
       "4  0.194805       unknown   single    unknown         no           -0.328918   \n",
       "\n",
       "  housing_loan personal_loan contact_method  day  month  duration  \\\n",
       "0          yes            no        unknown    5      5  0.373272   \n",
       "1          yes            no        unknown    5      5 -0.133641   \n",
       "2          yes           yes        unknown    5      5 -0.479263   \n",
       "3          yes            no        unknown    5      5 -0.405530   \n",
       "4           no            no        unknown    5      5  0.082949   \n",
       "\n",
       "   campaign_contacts  prev_days  previous_contacts prev_outcome term_deposit  \n",
       "0                0.0        0.0                0.0      unknown           no  \n",
       "1                0.0        0.0                0.0      unknown           no  \n",
       "2                0.0        0.0                0.0      unknown           no  \n",
       "3                0.0        0.0                0.0      unknown           no  \n",
       "4                0.0        0.0                0.0      unknown           no  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#decided also here that I should do campaign contacts\n",
    "preproc(df2, 'campaign_contacts', MinMaxScaler())\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting dummies now for the categorical data\n",
    "#df_ready = this dataframe is ready for modeling\n",
    "df_ready = pd.get_dummies(df2, columns = ['job','marital','education','in_default','housing_loan','personal_loan','contact_method','prev_outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['age', 'avg_yearly_balance', 'day', 'month', 'duration',\n",
       "       'campaign_contacts', 'prev_days', 'previous_contacts', 'term_deposit',\n",
       "       'job_admin.', 'job_blue-collar', 'job_entrepreneur', 'job_housemaid',\n",
       "       'job_management', 'job_retired', 'job_self-employed', 'job_services',\n",
       "       'job_student', 'job_technician', 'job_unemployed', 'job_unknown',\n",
       "       'marital_divorced', 'marital_married', 'marital_single',\n",
       "       'education_primary', 'education_secondary', 'education_tertiary',\n",
       "       'education_unknown', 'in_default_no', 'in_default_yes',\n",
       "       'housing_loan_no', 'housing_loan_yes', 'personal_loan_no',\n",
       "       'personal_loan_yes', 'contact_method_cellular',\n",
       "       'contact_method_telephone', 'contact_method_unknown',\n",
       "       'prev_outcome_failure', 'prev_outcome_other', 'prev_outcome_success',\n",
       "       'prev_outcome_unknown'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ready.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Models\n",
    "\n",
    "I will be running three baseline models with default parameters to test the predictive capability. Tune as necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "X = df_ready.drop(columns = ['term_deposit'])\n",
    "y = df_ready['term_deposit']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 44)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8998621165115478, Test Score: 0.9012064343163538 \n",
      "\n",
      "Cs: 10. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.95     13107\n",
      "         yes       0.70      0.33      0.45      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.81      0.65      0.70     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n",
      "Train Score: 0.8998333907847869, Test Score: 0.9012734584450403 \n",
      "\n",
      "Cs: 12. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.95     13107\n",
      "         yes       0.70      0.33      0.45      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.81      0.66      0.70     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Cs: 14. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.95     13107\n",
      "         yes       0.70      0.33      0.45      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.81      0.66      0.70     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9014075067024129 \n",
      "\n",
      "Cs: 16. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.95     13107\n",
      "         yes       0.70      0.33      0.45      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.81      0.65      0.70     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n",
      "Train Score: 0.8998621165115478, Test Score: 0.9014075067024129 \n",
      "\n",
      "Cs: 18. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.95     13107\n",
      "         yes       0.70      0.33      0.45      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.81      0.65      0.70     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n",
      "Train Score: 0.8998621165115478, Test Score: 0.9015415549597855 \n",
      "\n",
      "Cs: 20. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.95     13107\n",
      "         yes       0.70      0.33      0.45      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.81      0.66      0.70     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression CV\n",
    "for i in range(10,21,2):\n",
    "    clf = LogisticRegressionCV(cv=3, Cs = i, random_state=44, max_iter = 1500).fit(X_train, y_train)\n",
    "    clf_predictions = clf.predict(X_test)\n",
    "    clf_train_score = clf.score(X_train, y_train)\n",
    "    clf_test_score = clf.score(X_test, y_test)\n",
    "    print(\"Train Score: {}, Test Score: {} \\n\".format(clf_train_score, clf_test_score))\n",
    "    print(\"Cs: {}. \\n{}\".format(i, classification_report(y_test, clf_predictions)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0746327  0.6995806  0.02754351 ... 0.06392012 0.66884846 0.01998895]\n",
      "[0.04230711 0.16225694 0.053066   ... 0.03232473 0.025209   0.06917619]\n"
     ]
    }
   ],
   "source": [
    "#the order is no, yes, let's focus on the yes\n",
    "clfproba = clf.predict_proba(X_test)[:,1]\n",
    "print(clfproba)\n",
    "clfprobatrain = clf.predict_proba(X_train)[:,1]\n",
    "print(clfprobatrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefficient</th>\n",
       "      <th>Abs_Coefficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.010840</td>\n",
       "      <td>0.010840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <td>0.029405</td>\n",
       "      <td>0.029405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>-0.005246</td>\n",
       "      <td>0.005246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>month</th>\n",
       "      <td>-0.017539</td>\n",
       "      <td>0.017539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>duration</th>\n",
       "      <td>0.859012</td>\n",
       "      <td>0.859012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>campaign_contacts</th>\n",
       "      <td>-4.809073</td>\n",
       "      <td>4.809073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_days</th>\n",
       "      <td>-0.000106</td>\n",
       "      <td>0.000106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous_contacts</th>\n",
       "      <td>0.051427</td>\n",
       "      <td>0.051427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_admin.</th>\n",
       "      <td>0.193715</td>\n",
       "      <td>0.193715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_blue-collar</th>\n",
       "      <td>-0.148794</td>\n",
       "      <td>0.148794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_entrepreneur</th>\n",
       "      <td>-0.309368</td>\n",
       "      <td>0.309368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_housemaid</th>\n",
       "      <td>-0.371037</td>\n",
       "      <td>0.371037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_management</th>\n",
       "      <td>-0.000304</td>\n",
       "      <td>0.000304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_retired</th>\n",
       "      <td>0.582960</td>\n",
       "      <td>0.582960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_self-employed</th>\n",
       "      <td>-0.252542</td>\n",
       "      <td>0.252542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_services</th>\n",
       "      <td>-0.113171</td>\n",
       "      <td>0.113171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_student</th>\n",
       "      <td>0.684426</td>\n",
       "      <td>0.684426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_technician</th>\n",
       "      <td>-0.018214</td>\n",
       "      <td>0.018214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_unemployed</th>\n",
       "      <td>-0.019383</td>\n",
       "      <td>0.019383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>job_unknown</th>\n",
       "      <td>-0.195707</td>\n",
       "      <td>0.195707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_divorced</th>\n",
       "      <td>0.033654</td>\n",
       "      <td>0.033654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_married</th>\n",
       "      <td>-0.165645</td>\n",
       "      <td>0.165645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>marital_single</th>\n",
       "      <td>0.164571</td>\n",
       "      <td>0.164571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_primary</th>\n",
       "      <td>-0.240654</td>\n",
       "      <td>0.240654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_secondary</th>\n",
       "      <td>-0.012608</td>\n",
       "      <td>0.012608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_tertiary</th>\n",
       "      <td>0.235825</td>\n",
       "      <td>0.235825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>education_unknown</th>\n",
       "      <td>0.050017</td>\n",
       "      <td>0.050017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_default_no</th>\n",
       "      <td>0.053313</td>\n",
       "      <td>0.053313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>in_default_yes</th>\n",
       "      <td>-0.020733</td>\n",
       "      <td>0.020733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_loan_no</th>\n",
       "      <td>0.390091</td>\n",
       "      <td>0.390091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>housing_loan_yes</th>\n",
       "      <td>-0.357510</td>\n",
       "      <td>0.357510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal_loan_no</th>\n",
       "      <td>0.275839</td>\n",
       "      <td>0.275839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>personal_loan_yes</th>\n",
       "      <td>-0.243259</td>\n",
       "      <td>0.243259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_method_cellular</th>\n",
       "      <td>0.417475</td>\n",
       "      <td>0.417475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_method_telephone</th>\n",
       "      <td>0.361502</td>\n",
       "      <td>0.361502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contact_method_unknown</th>\n",
       "      <td>-0.746397</td>\n",
       "      <td>0.746397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_outcome_failure</th>\n",
       "      <td>-0.545485</td>\n",
       "      <td>0.545485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_outcome_other</th>\n",
       "      <td>-0.243383</td>\n",
       "      <td>0.243383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_outcome_success</th>\n",
       "      <td>1.673286</td>\n",
       "      <td>1.673286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prev_outcome_unknown</th>\n",
       "      <td>-0.851837</td>\n",
       "      <td>0.851837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Coefficient  Abs_Coefficient\n",
       "age                          0.010840         0.010840\n",
       "avg_yearly_balance           0.029405         0.029405\n",
       "day                         -0.005246         0.005246\n",
       "month                       -0.017539         0.017539\n",
       "duration                     0.859012         0.859012\n",
       "campaign_contacts           -4.809073         4.809073\n",
       "prev_days                   -0.000106         0.000106\n",
       "previous_contacts            0.051427         0.051427\n",
       "job_admin.                   0.193715         0.193715\n",
       "job_blue-collar             -0.148794         0.148794\n",
       "job_entrepreneur            -0.309368         0.309368\n",
       "job_housemaid               -0.371037         0.371037\n",
       "job_management              -0.000304         0.000304\n",
       "job_retired                  0.582960         0.582960\n",
       "job_self-employed           -0.252542         0.252542\n",
       "job_services                -0.113171         0.113171\n",
       "job_student                  0.684426         0.684426\n",
       "job_technician              -0.018214         0.018214\n",
       "job_unemployed              -0.019383         0.019383\n",
       "job_unknown                 -0.195707         0.195707\n",
       "marital_divorced             0.033654         0.033654\n",
       "marital_married             -0.165645         0.165645\n",
       "marital_single               0.164571         0.164571\n",
       "education_primary           -0.240654         0.240654\n",
       "education_secondary         -0.012608         0.012608\n",
       "education_tertiary           0.235825         0.235825\n",
       "education_unknown            0.050017         0.050017\n",
       "in_default_no                0.053313         0.053313\n",
       "in_default_yes              -0.020733         0.020733\n",
       "housing_loan_no              0.390091         0.390091\n",
       "housing_loan_yes            -0.357510         0.357510\n",
       "personal_loan_no             0.275839         0.275839\n",
       "personal_loan_yes           -0.243259         0.243259\n",
       "contact_method_cellular      0.417475         0.417475\n",
       "contact_method_telephone     0.361502         0.361502\n",
       "contact_method_unknown      -0.746397         0.746397\n",
       "prev_outcome_failure        -0.545485         0.545485\n",
       "prev_outcome_other          -0.243383         0.243383\n",
       "prev_outcome_success         1.673286         1.673286\n",
       "prev_outcome_unknown        -0.851837         0.851837"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coef = pd.DataFrame(index = X.columns, data = clf.coef_[0, :], columns = ['Coefficient'])\n",
    "#Here the odds that campaign contacts and previous succeses have an impact on 'yes' are high\n",
    "df_coef['Abs_Coefficient'] = abs(clf.coef_[0])\n",
    "df_coef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8998621165115478 0.9015415549597855\n"
     ]
    }
   ],
   "source": [
    "clf_predictions = clf.predict(X_test)\n",
    "clf_train_score = clf.score(X_train, y_train)\n",
    "clf_test_score = clf.score(X_test, y_test)\n",
    "print(clf_train_score, clf_test_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forests Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8949212915086752, Test Score: 0.8901474530831099 \n",
      "\n",
      "Depth: 5. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.89      1.00      0.94     13107\n",
      "         yes       0.82      0.12      0.21      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.86      0.56      0.58     14920\n",
      "weighted avg       0.88      0.89      0.85     14920\n",
      "\n",
      "Train Score: 0.9149718487877744, Test Score: 0.8977882037533512 \n",
      "\n",
      "Depth: 10. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.90      0.99      0.94     13107\n",
      "         yes       0.79      0.22      0.34      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.84      0.60      0.64     14920\n",
      "weighted avg       0.89      0.90      0.87     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Depth: 15. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.92      0.98      0.95     13107\n",
      "         yes       0.77      0.38      0.51      1813\n",
      "\n",
      "    accuracy                           0.91     14920\n",
      "   macro avg       0.85      0.68      0.73     14920\n",
      "weighted avg       0.90      0.91      0.90     14920\n",
      "\n",
      "Train Score: 0.992387682408365, Test Score: 0.9154825737265415 \n",
      "\n",
      "Depth: 20. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.95     13107\n",
      "         yes       0.76      0.44      0.56      1813\n",
      "\n",
      "    accuracy                           0.92     14920\n",
      "   macro avg       0.84      0.71      0.76     14920\n",
      "weighted avg       0.91      0.92      0.91     14920\n",
      "\n",
      "Train Score: 0.9992818568309778, Test Score: 0.9140080428954424 \n",
      "\n",
      "Depth: 25. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.95     13107\n",
      "         yes       0.74      0.45      0.56      1813\n",
      "\n",
      "    accuracy                           0.91     14920\n",
      "   macro avg       0.83      0.71      0.76     14920\n",
      "weighted avg       0.91      0.91      0.90     14920\n",
      "\n",
      "Train Score: 0.9999712742732391, Test Score: 0.9152815013404826 \n",
      "\n",
      "Depth: 30. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.95     13107\n",
      "         yes       0.75      0.45      0.57      1813\n",
      "\n",
      "    accuracy                           0.92     14920\n",
      "   macro avg       0.84      0.72      0.76     14920\n",
      "weighted avg       0.91      0.92      0.91     14920\n",
      "\n",
      "Train Score: 0.9999712742732391, Test Score: 0.9157506702412869 \n",
      "\n",
      "Depth: 35. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.93      0.98      0.95     13107\n",
      "         yes       0.75      0.46      0.57      1813\n",
      "\n",
      "    accuracy                           0.92     14920\n",
      "   macro avg       0.84      0.72      0.76     14920\n",
      "weighted avg       0.91      0.92      0.91     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#To make later parameter tuning easier, let's make sure we check multiple depths. \n",
    "\n",
    "for i in range(5,40,5):\n",
    "    rfc = RandomForestClassifier(max_depth=i, random_state=44).fit(X_train, y_train)\n",
    "    rfc_predictions = rfc.predict(X_test)\n",
    "    rfc_train_score = rfc.score(X_train, y_train)\n",
    "    rfc_test_score = rfc.score(X_test, y_test)\n",
    "    print(\"Train Score: {}, Test Score: {} \\n\".format(rfc_train_score, rfc_test_score))\n",
    "    print(\"Depth: {}. \\n{}\".format(i, classification_report(y_test, rfc_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important factor here is recall, we want to try to get recall as high as possible so that we are able to correctly identify customers. 0.45 is higher than before, if our precision falters, but our recall is high, this is acceptable as a few misplaced man-hours is less impactful than missed opportunities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After running more baselines, we will revisit this using the probabilities from predict_proba_ to determine tweak. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNN baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9418304033092038, Test_Score: 0.892225201072386 \n",
      "\n",
      "Neighbors: 2. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.90      0.98      0.94     13107\n",
      "         yes       0.64      0.25      0.36      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.77      0.62      0.65     14920\n",
      "weighted avg       0.87      0.89      0.87     14920\n",
      "\n",
      "Train Score: 0.9235321153625187, Test_Score: 0.8928954423592493 \n",
      "\n",
      "Neighbors: 4. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.94     13107\n",
      "         yes       0.64      0.27      0.38      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.77      0.62      0.66     14920\n",
      "weighted avg       0.87      0.89      0.87     14920\n",
      "\n",
      "Train Score: 0.9159485234976444, Test_Score: 0.8931635388739947 \n",
      "\n",
      "Neighbors: 6. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.94     13107\n",
      "         yes       0.64      0.27      0.38      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.77      0.63      0.66     14920\n",
      "weighted avg       0.87      0.89      0.87     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Neighbors: 8. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.94     13107\n",
      "         yes       0.65      0.29      0.40      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.78      0.63      0.67     14920\n",
      "weighted avg       0.88      0.89      0.88     14920\n",
      "\n",
      "Train Score: 0.9082213029989659, Test_Score: 0.8940348525469168 \n",
      "\n",
      "Neighbors: 10. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.91      0.98      0.94     13107\n",
      "         yes       0.65      0.28      0.39      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.78      0.63      0.66     14920\n",
      "weighted avg       0.88      0.89      0.87     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "#let's do some initial testing with different neighbors\n",
    "for i in range(2,12,2):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i).fit(X_train, y_train)\n",
    "    knn_predictions = knn.predict(X_test)\n",
    "    knn_train_score = knn.score(X_train, y_train)\n",
    "    knn_test_score = knn.score(X_test, y_test)\n",
    "    print(\"Train Score: {}, Test_Score: {} \\n\".format(knn_train_score, knn_test_score))\n",
    "    print(\"Neighbors: {}. \\n{}\".format(i, classification_report(y_test, knn_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8140009192232563, Test_Score: 0.813337801608579 \n",
      "\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          no       0.94      0.85      0.89     13107\n",
      "         yes       0.34      0.58      0.43      1813\n",
      "\n",
      "    accuracy                           0.81     14920\n",
      "   macro avg       0.64      0.71      0.66     14920\n",
      "weighted avg       0.86      0.81      0.83     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#simple naive bayes just to see what a very simple model handles.\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "nb = GaussianNB()\n",
    "nb.fit(X_train, y_train)\n",
    "nb_predictions = nb.predict(X_test)\n",
    "nb_train_score = nb.score(X_train, y_train)\n",
    "nb_test_score = nb.score(X_test, y_test)\n",
    "print(\"Train Score: {}, Test_Score: {} \\n\".format(nb_train_score, nb_test_score))\n",
    "print(\"\\n{}\".format(classification_report(y_test, nb_predictions)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go ahead and tweak the best of each. Again, we're going for high recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.01 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       1.00      0.09      0.17     13107\n",
      "        True       0.13      1.00      0.23      1813\n",
      "\n",
      "    accuracy                           0.20     14920\n",
      "   macro avg       0.57      0.55      0.20     14920\n",
      "weighted avg       0.89      0.20      0.18     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.025 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.31      0.47     13107\n",
      "        True       0.16      0.99      0.28      1813\n",
      "\n",
      "    accuracy                           0.39     14920\n",
      "   macro avg       0.58      0.65      0.37     14920\n",
      "weighted avg       0.89      0.39      0.44     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.05 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.55      0.71     13107\n",
      "        True       0.23      0.96      0.37      1813\n",
      "\n",
      "    accuracy                           0.60     14920\n",
      "   macro avg       0.61      0.75      0.54     14920\n",
      "weighted avg       0.90      0.60      0.66     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.075 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.70      0.82     13107\n",
      "        True       0.29      0.91      0.44      1813\n",
      "\n",
      "    accuracy                           0.72     14920\n",
      "   macro avg       0.64      0.80      0.63     14920\n",
      "weighted avg       0.90      0.72      0.77     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.1 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.79      0.87     13107\n",
      "        True       0.36      0.86      0.51      1813\n",
      "\n",
      "    accuracy                           0.80     14920\n",
      "   macro avg       0.67      0.83      0.69     14920\n",
      "weighted avg       0.90      0.80      0.83     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.15 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.88      0.92     13107\n",
      "        True       0.45      0.73      0.55      1813\n",
      "\n",
      "    accuracy                           0.86     14920\n",
      "   macro avg       0.70      0.80      0.74     14920\n",
      "weighted avg       0.90      0.86      0.87     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.2 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.95      0.92      0.93     13107\n",
      "        True       0.51      0.63      0.56      1813\n",
      "\n",
      "    accuracy                           0.88     14920\n",
      "   macro avg       0.73      0.77      0.75     14920\n",
      "weighted avg       0.89      0.88      0.89     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.25 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.94      0.94     13107\n",
      "        True       0.56      0.55      0.55      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.75      0.74      0.75     14920\n",
      "weighted avg       0.89      0.89      0.89     14920\n",
      "\n",
      "Train Score: 0.8998046650580259, Test Score: 0.9015415549597855 \n",
      "\n",
      "Probability Threshold: 0.3 \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.95      0.94     13107\n",
      "        True       0.60      0.49      0.54      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.76      0.72      0.74     14920\n",
      "weighted avg       0.89      0.90      0.89     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Logistic Regression CV, using predict_proba\n",
    "#testing different thresholds of probability\n",
    "proba_thresh_list = [0.01, 0.025, 0.05,0.075,0.1,0.15,0.2,0.25,0.3]\n",
    "\n",
    "for i in proba_thresh_list:\n",
    "    clf = LogisticRegressionCV(cv=3, Cs = 14, random_state=44, max_iter = 1500).fit(X_train, y_train)\n",
    "    clf_predictions = clf.predict(X_test)\n",
    "    clf_train_score = clf.score(X_train, y_train)\n",
    "    clf_test_score = clf.score(X_test, y_test)\n",
    "    clf_proba = clf.predict_proba(X_test)\n",
    "    clf_lower_thresh = (clf_proba[:,1] > i)\n",
    "    print(\"Train Score: {}, Test Score: {} \\n\".format(clf_train_score, clf_test_score))\n",
    "    print(\"Probability Threshold: {} \\n{}\".format(i, classification_report((y_test == 'yes'), clf_lower_thresh)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted lower threshold, higher recall, but very low precision. Let's continue on and see how the other models fare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.01. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.39     13107\n",
      "           1       0.15      1.00      0.27      1813\n",
      "\n",
      "    accuracy                           0.33     14920\n",
      "   macro avg       0.58      0.62      0.33     14920\n",
      "weighted avg       0.90      0.33      0.37     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.025. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67     13107\n",
      "           1       0.22      0.99      0.36      1813\n",
      "\n",
      "    accuracy                           0.56     14920\n",
      "   macro avg       0.61      0.75      0.51     14920\n",
      "weighted avg       0.90      0.56      0.63     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.05. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.68      0.81     13107\n",
      "           1       0.30      0.98      0.45      1813\n",
      "\n",
      "    accuracy                           0.71     14920\n",
      "   macro avg       0.65      0.83      0.63     14920\n",
      "weighted avg       0.91      0.71      0.76     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.075. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.75      0.86     13107\n",
      "           1       0.35      0.96      0.51      1813\n",
      "\n",
      "    accuracy                           0.78     14920\n",
      "   macro avg       0.67      0.85      0.68     14920\n",
      "weighted avg       0.91      0.78      0.81     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.1. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.80      0.88     13107\n",
      "           1       0.39      0.93      0.55      1813\n",
      "\n",
      "    accuracy                           0.81     14920\n",
      "   macro avg       0.69      0.87      0.72     14920\n",
      "weighted avg       0.92      0.81      0.84     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.15. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.85      0.91     13107\n",
      "           1       0.45      0.88      0.60      1813\n",
      "\n",
      "    accuracy                           0.86     14920\n",
      "   macro avg       0.72      0.87      0.75     14920\n",
      "weighted avg       0.92      0.86      0.87     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.2. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.89      0.93     13107\n",
      "           1       0.51      0.83      0.63      1813\n",
      "\n",
      "    accuracy                           0.88     14920\n",
      "   macro avg       0.74      0.86      0.78     14920\n",
      "weighted avg       0.92      0.88      0.89     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.25. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.91      0.94     13107\n",
      "           1       0.56      0.78      0.65      1813\n",
      "\n",
      "    accuracy                           0.90     14920\n",
      "   macro avg       0.76      0.85      0.80     14920\n",
      "weighted avg       0.92      0.90      0.91     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.3. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.93      0.95     13107\n",
      "           1       0.60      0.71      0.65      1813\n",
      "\n",
      "    accuracy                           0.91     14920\n",
      "   macro avg       0.78      0.82      0.80     14920\n",
      "weighted avg       0.91      0.91      0.91     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#RandomForests, using predict_proba\n",
    "#testing different thresholds of probability\n",
    "\n",
    "for i in proba_thresh_list:\n",
    "    rfc = RandomForestClassifier(max_depth=15, random_state=44).fit(X_train, y_train)\n",
    "    rfc_predictions = rfc.predict(X_test)\n",
    "    rfc_train_score = rfc.score(X_train, y_train)\n",
    "    rfc_test_score = rfc.score(X_test, y_test)\n",
    "    rfc_proba = rfc.predict_proba(X_test)\n",
    "    rfc_lower_thresh = (rfc_proba[:,1] > i).astype('int')\n",
    "    print(\"Train Score: {}, Test Score: {} \\n\".format(rfc_train_score, rfc_test_score))\n",
    "    print(\"Probability Threshold: {}. \\n{}\".format(i, classification_report((y_test == 'yes').astype('int'), rfc_lower_thresh)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.01. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.78      0.87     13107\n",
      "        True       0.35      0.88      0.50      1813\n",
      "\n",
      "    accuracy                           0.79     14920\n",
      "   macro avg       0.67      0.83      0.68     14920\n",
      "weighted avg       0.90      0.79      0.82     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.025. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.78      0.87     13107\n",
      "        True       0.35      0.88      0.50      1813\n",
      "\n",
      "    accuracy                           0.79     14920\n",
      "   macro avg       0.67      0.83      0.68     14920\n",
      "weighted avg       0.90      0.79      0.82     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.05. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.78      0.87     13107\n",
      "        True       0.35      0.88      0.50      1813\n",
      "\n",
      "    accuracy                           0.79     14920\n",
      "   macro avg       0.67      0.83      0.68     14920\n",
      "weighted avg       0.90      0.79      0.82     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.075. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.78      0.87     13107\n",
      "        True       0.35      0.88      0.50      1813\n",
      "\n",
      "    accuracy                           0.79     14920\n",
      "   macro avg       0.67      0.83      0.68     14920\n",
      "weighted avg       0.90      0.79      0.82     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.1. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.98      0.78      0.87     13107\n",
      "        True       0.35      0.88      0.50      1813\n",
      "\n",
      "    accuracy                           0.79     14920\n",
      "   macro avg       0.67      0.83      0.68     14920\n",
      "weighted avg       0.90      0.79      0.82     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.15. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.88      0.92     13107\n",
      "        True       0.47      0.73      0.57      1813\n",
      "\n",
      "    accuracy                           0.87     14920\n",
      "   macro avg       0.71      0.81      0.74     14920\n",
      "weighted avg       0.90      0.87      0.88     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.2. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.96      0.88      0.92     13107\n",
      "        True       0.47      0.73      0.57      1813\n",
      "\n",
      "    accuracy                           0.87     14920\n",
      "   macro avg       0.71      0.81      0.74     14920\n",
      "weighted avg       0.90      0.87      0.88     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.25. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.93      0.94     13107\n",
      "        True       0.54      0.58      0.56      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.74      0.76      0.75     14920\n",
      "weighted avg       0.89      0.89      0.89     14920\n",
      "\n",
      "Train Score: 0.9113236814891417, Test_Score: 0.8942359249329759 \n",
      "\n",
      "Probability Threshold: 0.3. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.93      0.94     13107\n",
      "        True       0.54      0.58      0.56      1813\n",
      "\n",
      "    accuracy                           0.89     14920\n",
      "   macro avg       0.74      0.76      0.75     14920\n",
      "weighted avg       0.89      0.89      0.89     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#KNN probability testing\n",
    "\n",
    "for i in proba_thresh_list:\n",
    "    knn = KNeighborsClassifier(n_neighbors=8).fit(X_train, y_train)\n",
    "    knn_predictions = knn.predict(X_test)\n",
    "    knn_train_score = knn.score(X_train, y_train)\n",
    "    knn_test_score = knn.score(X_test, y_test)\n",
    "    knn_proba = knn.predict_proba(X_test)\n",
    "    knn_lower_thresh = (knn_proba[:,1] > i)\n",
    "    print(\"Train Score: {}, Test_Score: {} \\n\".format(knn_train_score, knn_test_score))\n",
    "    print(\"Probability Threshold: {}. \\n{}\".format(i, classification_report((y_test == 'yes'), knn_lower_thresh)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks as though with this edit, RandomForests is doing the best here. We can see that the with a probability threshold of 0.2 we are getting: \n",
    "Probability Threshold: 0.2. \n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.97      0.89      0.93     13107\n",
    "           1       0.51      0.83      0.63      1813\n",
    "           \n",
    "\n",
    "This allows shows us that we will be filling our picks just over half with incorrect picks, but we are securing 0.83 of the correct choices.\n",
    "\n",
    "In sales terms, the average call 4.3 minutes. We currently have a 'yes' rate of 11.68% of customers. But we have 50,000 customers (about) at 4.3 minutes per 1 contact is 215,000 minutes to secure 5840 deposits. Thats 1 term deposit every 36.8 minutes. However if we instead decide to use the model. We will still be securing 4847 deposits. But cutting the outgoing calls to only 9504 customers. At 4.3 minutes avg for one contact, this is 40,867 minutes and a sale every 8.4 minutes. At the cost of 17% of the term deposits, the company can save 174,133 minutes, i.e 2,902 hours of labor-time. Let's say the call center employee costs 20 dollars an hour (total including packages) for the employer. this saves 58, 040 dollars during the campaign time. This number should be compared to the profit that is lost if this model were to be adopted. There may also be other non-material value in each sale, such as further customer loyalty and susceptability to future sales which could be accounted for. \n",
    "\n",
    "However, this approach is not binary. Now we can venture forth and create a model that is to tier the employees based on their likelihood to sign up. This can at least become a base from which to spring a campaign. \n",
    "\n",
    "Before we do that, I would like to idealize a few options based on this model just to see if there the previous thresholds of 0.15, and 0.1 .etc are plausible towards this goal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating a small function to spit out some stats\n",
    "#creating tuples of reported info\n",
    "rf_01 = (\"1%\", .15, 1.0)\n",
    "rf_025 = (\"2.5%\", .22, .99)\n",
    "rf_05 = (\"5%\", .3, .98)\n",
    "rf_075 = (\"7.5%\", .35, .96)\n",
    "rf_10 = (\"10%\", .39, .93)\n",
    "rf_15 = (\"15%\", .45, .87)\n",
    "rf_20 = ('20%', .51, .83)\n",
    "\n",
    "rf_list = [rf_01, rf_025, rf_05, rf_075, rf_10, rf_15, rf_20]\n",
    "\n",
    "def trade_off_report(rf_tuple, cust = 50000, conv_perc = 0.1168, avg_dur = 4.3):\n",
    "    nm_conv = round((cust * conv_perc),2)\n",
    "    nm_dur_total = round((cust * avg_dur),2)\n",
    "    nm_conv_interval = round((nm_dur_total / nm_conv),2)\n",
    "    m_conv = round((nm_conv * rf_tuple[2]),2)\n",
    "    m_dur_total = round(((m_conv / rf_tuple[1]) * avg_dur),2) #getting all customers that would be called for 'yes', then multiplying by duration\n",
    "    m_conv_interval = round((m_dur_total / m_conv),2)\n",
    "    print(\"Threshold: {}\\nNo Model Conversions: {}\\nModel Conversions: {}\\nNo Model Minutes used: {}\\nModel Minutes Used: {}\\n\\\n",
    "    No Model Conversion Interval: {}\\nModel Conversion Interval: {}\\n\".format(rf_tuple[0], nm_conv, m_conv, nm_dur_total, m_dur_total, nm_conv_interval, m_conv_interval))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5840.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 167413.33\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 28.67\n",
      "\n",
      "Threshold: 2.5\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5781.6\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 113004.0\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 19.55\n",
      "\n",
      "Threshold: 5%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5723.2\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 82032.53\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 14.33\n",
      "\n",
      "Threshold: 7.5%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5606.4\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 68878.63\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 12.29\n",
      "\n",
      "Threshold: 10%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5431.2\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 59882.46\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 11.03\n",
      "\n",
      "Threshold: 15%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5080.8\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 48549.87\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 9.56\n",
      "\n",
      "Threshold: 20%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 4847.2\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 40868.55\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 8.43\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in rf_list:\n",
    "    trade_off_report(rf_tuple = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this shows that even with a model threshold at 0.01%, the company can still save time: 47587 speculated minutes. And this threshold would lose 0 sales. Even the safest threshold allows us to maintain sales. However, I have to wonder. is there a threshold between 1% and 2.5% that allows us to maximize? No point in wondering for too long, let's put it the test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.01. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.24      0.39     13107\n",
      "           1       0.15      1.00      0.27      1813\n",
      "\n",
      "    accuracy                           0.33     14920\n",
      "   macro avg       0.58      0.62      0.33     14920\n",
      "weighted avg       0.90      0.33      0.37     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.011. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.26      0.41     13107\n",
      "           1       0.16      1.00      0.27      1813\n",
      "\n",
      "    accuracy                           0.35     14920\n",
      "   macro avg       0.58      0.63      0.34     14920\n",
      "weighted avg       0.90      0.35      0.40     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.011999999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.28      0.44     13107\n",
      "           1       0.16      1.00      0.28      1813\n",
      "\n",
      "    accuracy                           0.37     14920\n",
      "   macro avg       0.58      0.64      0.36     14920\n",
      "weighted avg       0.90      0.37      0.42     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.012999999999999998. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.30      0.47     13107\n",
      "           1       0.17      1.00      0.28      1813\n",
      "\n",
      "    accuracy                           0.39     14920\n",
      "   macro avg       0.58      0.65      0.38     14920\n",
      "weighted avg       0.90      0.39      0.44     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.013999999999999997. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.33      0.49     13107\n",
      "           1       0.17      1.00      0.29      1813\n",
      "\n",
      "    accuracy                           0.41     14920\n",
      "   macro avg       0.58      0.66      0.39     14920\n",
      "weighted avg       0.90      0.41      0.47     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.014999999999999996. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.35      0.52     13107\n",
      "           1       0.17      1.00      0.30      1813\n",
      "\n",
      "    accuracy                           0.43     14920\n",
      "   macro avg       0.59      0.67      0.41     14920\n",
      "weighted avg       0.90      0.43      0.49     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.015999999999999993. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.37      0.54     13107\n",
      "           1       0.18      1.00      0.30      1813\n",
      "\n",
      "    accuracy                           0.44     14920\n",
      "   macro avg       0.59      0.68      0.42     14920\n",
      "weighted avg       0.90      0.44      0.51     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.016999999999999994. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.39      0.56     13107\n",
      "           1       0.18      1.00      0.31      1813\n",
      "\n",
      "    accuracy                           0.46     14920\n",
      "   macro avg       0.59      0.69      0.43     14920\n",
      "weighted avg       0.90      0.46      0.53     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.017999999999999995. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.40      0.58     13107\n",
      "           1       0.19      1.00      0.32      1813\n",
      "\n",
      "    accuracy                           0.48     14920\n",
      "   macro avg       0.59      0.70      0.45     14920\n",
      "weighted avg       0.90      0.48      0.54     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.018999999999999993. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.42      0.59     13107\n",
      "           1       0.19      0.99      0.32      1813\n",
      "\n",
      "    accuracy                           0.49     14920\n",
      "   macro avg       0.59      0.71      0.46     14920\n",
      "weighted avg       0.90      0.49      0.56     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.01999999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.44      0.61     13107\n",
      "           1       0.20      0.99      0.33      1813\n",
      "\n",
      "    accuracy                           0.50     14920\n",
      "   macro avg       0.60      0.72      0.47     14920\n",
      "weighted avg       0.90      0.50      0.57     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.02099999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.45      0.62     13107\n",
      "           1       0.20      0.99      0.33      1813\n",
      "\n",
      "    accuracy                           0.52     14920\n",
      "   macro avg       0.60      0.72      0.48     14920\n",
      "weighted avg       0.90      0.52      0.58     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.021999999999999992. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.46      0.63     13107\n",
      "           1       0.20      0.99      0.34      1813\n",
      "\n",
      "    accuracy                           0.53     14920\n",
      "   macro avg       0.60      0.73      0.49     14920\n",
      "weighted avg       0.90      0.53      0.60     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.02299999999999999. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.48      0.65     13107\n",
      "           1       0.21      0.99      0.34      1813\n",
      "\n",
      "    accuracy                           0.54     14920\n",
      "   macro avg       0.60      0.74      0.50     14920\n",
      "weighted avg       0.90      0.54      0.61     14920\n",
      "\n",
      "Train Score: 0.963144892565782, Test Score: 0.9109249329758713 \n",
      "\n",
      "Probability Threshold: 0.023999999999999987. \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.49      0.66     13107\n",
      "           1       0.21      0.99      0.35      1813\n",
      "\n",
      "    accuracy                           0.55     14920\n",
      "   macro avg       0.61      0.74      0.50     14920\n",
      "weighted avg       0.90      0.55      0.62     14920\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#testing a tight range of threshold amounts\n",
    "\n",
    "for i in np.arange(0.01, 0.025, 0.001): \n",
    "    rfc = RandomForestClassifier(max_depth=15, random_state=44).fit(X_train, y_train)\n",
    "    rfc_predictions = rfc.predict(X_test)\n",
    "    rfc_train_score = rfc.score(X_train, y_train)\n",
    "    rfc_test_score = rfc.score(X_test, y_test)\n",
    "    rfc_proba = rfc.predict_proba(X_test)\n",
    "    rfc_lower_thresh = (rfc_proba[:,1] > i).astype('int')\n",
    "    print(\"Train Score: {}, Test Score: {} \\n\".format(rfc_train_score, rfc_test_score))\n",
    "    print(\"Probability Threshold: {}. \\n{}\".format(i, classification_report((y_test == 'yes').astype('int'), rfc_lower_thresh)))\n",
    "    \n",
    "#Note: this is slow, but necessary if we want to be absolutely sure of our maximization, each call saved adds up quickly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like the drop off is right at 1.8% let's see how this compares to 1% and 2.5%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 1%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5840.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 167413.33\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 28.67\n",
      "\n",
      "Threshold: 1.8%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5840.0\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 132168.42\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 22.63\n",
      "\n",
      "Threshold: 2.5%\n",
      "No Model Conversions: 5840.0\n",
      "Model Conversions: 5781.6\n",
      "No Model Minutes used: 215000.0\n",
      "Model Minutes Used: 113004.0\n",
      "    No Model Conversion Interval: 36.82\n",
      "Model Conversion Interval: 19.55\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_018 = (\"1.8%\", 0.19, 1.0)\n",
    "rf_tight_list = [rf_01, rf_018, rf_025]\n",
    "\n",
    "for i in rf_tight_list:\n",
    "    trade_off_report(rf_tuple = i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So if it was decided that no conversion loss was wanted, we could propose this model at a threshold of 1.8% and still reduce our minutes down by 52,832 i.e 880 hours. I believe that this type of improvement would be very benefical in maximizing worker-hours. We could cut more if we wanted to, it depends on how the bank is willing to balance hours spent with the response rate.\n",
    "\n",
    "\n",
    "As promised let's dig into the tiers. Based on the thresholds. We can use the random forest with the whole dataframe for this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>in_default</th>\n",
       "      <th>avg_yearly_balance</th>\n",
       "      <th>housing_loan</th>\n",
       "      <th>personal_loan</th>\n",
       "      <th>contact_method</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign_contacts</th>\n",
       "      <th>prev_days</th>\n",
       "      <th>previous_contacts</th>\n",
       "      <th>prev_outcome</th>\n",
       "      <th>term_deposit</th>\n",
       "      <th>probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>58</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>2143</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44</td>\n",
       "      <td>technician</td>\n",
       "      <td>single</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>29</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>33</td>\n",
       "      <td>entrepreneur</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1506</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>92</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>33</td>\n",
       "      <td>unknown</td>\n",
       "      <td>single</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>1</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>no</td>\n",
       "      <td>0.004</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age           job  marital  education in_default  avg_yearly_balance  \\\n",
       "0   58    management  married   tertiary         no                2143   \n",
       "1   44    technician   single  secondary         no                  29   \n",
       "2   33  entrepreneur  married  secondary         no                   2   \n",
       "3   47   blue-collar  married    unknown         no                1506   \n",
       "4   33       unknown   single    unknown         no                   1   \n",
       "\n",
       "  housing_loan personal_loan contact_method  day  month  duration  \\\n",
       "0          yes            no        unknown    5      5       261   \n",
       "1          yes            no        unknown    5      5       151   \n",
       "2          yes           yes        unknown    5      5        76   \n",
       "3          yes            no        unknown    5      5        92   \n",
       "4           no            no        unknown    5      5       198   \n",
       "\n",
       "   campaign_contacts  prev_days  previous_contacts prev_outcome term_deposit  \\\n",
       "0                  1         -1                  0      unknown           no   \n",
       "1                  1         -1                  0      unknown           no   \n",
       "2                  1         -1                  0      unknown           no   \n",
       "3                  1         -1                  0      unknown           no   \n",
       "4                  1         -1                  0      unknown           no   \n",
       "\n",
       "   probability  \n",
       "0        0.006  \n",
       "1        0.003  \n",
       "2        0.008  \n",
       "3        0.005  \n",
       "4        0.004  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc_whole_proba = rfc.predict_proba(df_ready.drop(columns ='term_deposit'))\n",
    "df_copy = df.copy()\n",
    "df_copy['probability'] = rfc_whole_proba[:,1]\n",
    "df_copy['probability'] = df_copy['probability'].round(3)\n",
    "df_copy.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tiering thet dataset\n",
    "df_copy['tier'] = pd.cut(df_copy['probability'],[0, 0.018, 0.4, 0.6, 1.0],labels=['tier_4', 'tier_3', 'tier_2', 'tier_1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tier_4       9\n",
       "tier_3    1548\n",
       "tier_2    1828\n",
       "tier_1    2425\n",
       "Name: tier, dtype: int64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.tier.loc[df_copy['term_deposit'] == 'yes'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it looks like we have a few lost travellers here. But we can attribute this to a reworking of the machine learning algorithm using all of the data rather than prior with just the training, then test set. missing 9 conversions is negligble in the grand scheme as we would still be saving a lot of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tier_4    19648\n",
       "tier_3    23621\n",
       "tier_2      574\n",
       "tier_1       75\n",
       "Name: tier, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy.tier.loc[df_copy['term_deposit'] == 'no'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we see that if we wanted to completely avoid calling tier_4 customers. We would be be reducing the customers contacted by 19857, only 9 of which, in this case, subscribed to a term deposit. So as you can see below, about half a percent of those customers were likely to sign up. Let's look at the chance of calling each tier based on their current success rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tier 4: 0.0005\n",
      "Tier 3: 0.0615\n",
      "Tier 2: 0.761\n",
      "Tier 1: 0.97\n"
     ]
    }
   ],
   "source": [
    "print(\"Tier 4: \" + str(round((9/19657),4)))\n",
    "print(\"Tier 3: \" + str(round((1548/25169),4)))\n",
    "print(\"Tier 2: \" + str(round((1828/2402),4)))\n",
    "print(\"Tier 1: \" + str(round((2425/2500),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By tiering the customers in this way, we can strike hardest where the customer is most likely to respond well. To finalize this segment, let's go ahead and print what an ideal dataframe would look like before a campaign."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    tier_4\n",
       "1    tier_4\n",
       "2    tier_4\n",
       "3    tier_4\n",
       "4    tier_4\n",
       "5    tier_4\n",
       "6    tier_4\n",
       "7    tier_4\n",
       "8    tier_4\n",
       "9    tier_4\n",
       "Name: tier, dtype: category\n",
       "Categories (4, object): [tier_4 < tier_3 < tier_2 < tier_1]"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_copy['tier'].head(10) #and that's it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
